from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Query
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
import pandas as pd
import numpy as np
import io
from typing import Optional, List

from models import get_db
from analysis.factor import FactorAnalysisAnalyzer

# å¿…é ˆã§ãªã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from factor_analyzer import FactorAnalyzer as FactorAnalyzerLib

    FACTOR_ANALYZER_AVAILABLE = True
except ImportError:
    FACTOR_ANALYZER_AVAILABLE = False

router = APIRouter(prefix="/factor", tags=["factor"])


@router.post("/analyze")
async def analyze_factor(
    file: UploadFile = File(...),
    session_name: str = Query(..., description="åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å"),
    description: Optional[str] = Query(None, description="åˆ†æã®èª¬æ˜"),
    tags: Optional[str] = Query(None, description="ã‚¿ã‚°ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰"),
    user_id: str = Query("default", description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
    n_factors: Optional[int] = Query(
        None, description="å› å­æ•°ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è‡ªå‹•æ±ºå®šï¼‰"
    ),
    rotation: str = Query("varimax", description="å›è»¢æ–¹æ³•"),
    standardize: bool = Query(True, description="ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–ã™ã‚‹ã‹"),
    db: Session = Depends(get_db),
):
    """å› å­åˆ†æã‚’å®Ÿè¡Œ"""
    try:
        print(f"=== å› å­åˆ†æAPIå‘¼ã³å‡ºã—é–‹å§‹ ===")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_name}")
        print(f"å› å­æ•°: {n_factors}, å›è»¢: {rotation}, æ¨™æº–åŒ–: {standardize}")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not file.filename.endswith(".csv"):
            raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™")

        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        contents = await file.read()
        try:
            csv_text = contents.decode("utf-8")
        except UnicodeDecodeError:
            csv_text = contents.decode("shift_jis")

        print(f"CSVãƒ†ã‚­ã‚¹ãƒˆ:\n{csv_text}")

        df = pd.read_csv(io.StringIO(csv_text), index_col=0)
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ :\n{df}")

        if df.empty:
            raise HTTPException(status_code=400, detail="ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡º
        numeric_df = df.select_dtypes(include=[np.number])
        if numeric_df.empty:
            raise HTTPException(
                status_code=400,
                detail="æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å› å­åˆ†æã«ã¯æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚",
            )

        # æ¬ æå€¤ã®å‡¦ç†
        if numeric_df.isnull().any().any():
            numeric_df = numeric_df.dropna()
            if numeric_df.empty:
                raise HTTPException(
                    status_code=400,
                    detail="æ¬ æå€¤ã‚’é™¤å»ã—ãŸçµæœã€ãƒ‡ãƒ¼ã‚¿ãŒç©ºã«ãªã‚Šã¾ã—ãŸã€‚",
                )

        # ã‚¿ã‚°å‡¦ç†
        tag_list = [tag.strip() for tag in tags.split(",")] if tags else []

        # åˆ†æå®Ÿè¡Œï¼ˆBaseAnalyzerã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ï¼‰
        analyzer = FactorAnalysisAnalyzer()
        response_data = analyzer.run_full_analysis(
            df=numeric_df,
            db=db,
            session_name=session_name,
            description=description,
            tags=tag_list,
            user_id=user_id,
            file=file,
            csv_text=csv_text,
            n_factors=n_factors,
            rotation=rotation,
            standardize=standardize,
        )

        print("=== å› å­åˆ†æAPIå‡¦ç†å®Œäº† ===")
        return JSONResponse(content=response_data)

    except HTTPException:
        raise
    except Exception as e:
        print(f"=== å› å­åˆ†æAPIå‡¦ç†ã‚¨ãƒ©ãƒ¼ ===")
        print(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500, detail=f"å› å­åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/methods")
async def get_factor_methods():
    """å› å­åˆ†æã§åˆ©ç”¨å¯èƒ½ãªæ‰‹æ³•ä¸€è¦§ã‚’å–å¾—"""
    methods = {
        "rotation_methods": [
            {
                "id": "varimax",
                "name": "ãƒãƒªãƒãƒƒã‚¯ã‚¹å›è»¢",
                "description": "ç›´äº¤å›è»¢ã€å› å­ã®è§£é‡ˆã‚’ç°¡å˜ã«ã™ã‚‹",
            },
            {
                "id": "quartimax",
                "name": "ã‚¯ã‚©ãƒ¼ãƒ†ã‚£ãƒãƒƒã‚¯ã‚¹å›è»¢",
                "description": "ç›´äº¤å›è»¢ã€å¤‰æ•°ã®è§£é‡ˆã‚’ç°¡å˜ã«ã™ã‚‹",
            },
        ],
        "guidelines": {
            "kmo_thresholds": {
                "excellent": {"value": 0.9, "label": "å„ªç§€"},
                "good": {"value": 0.8, "label": "è‰¯å¥½"},
                "adequate": {"value": 0.7, "label": "é©åˆ‡"},
                "poor": {"value": 0.6, "label": "ä¸è‰¯"},
                "unacceptable": {"value": 0.5, "label": "ä¸é©åˆ‡"},
            },
            "minimum_sample_size": "å¤‰æ•°æ•°ã®5-10å€",
            "minimum_variables": 3,
            "communality_threshold": 0.5,
        },
        "library_status": {
            "factor_analyzer": FACTOR_ANALYZER_AVAILABLE,
            "sklearn_alternative": True,
        },
    }

    if FACTOR_ANALYZER_AVAILABLE:
        methods["rotation_methods"].extend(
            [
                {
                    "id": "promax",
                    "name": "ãƒ—ãƒ­ãƒãƒƒã‚¯ã‚¹å›è»¢",
                    "description": "æ–œäº¤å›è»¢ã€å› å­é–“ã®ç›¸é–¢ã‚’è¨±å¯",
                },
                {
                    "id": "oblimin",
                    "name": "ã‚ªãƒ–ãƒªãƒŸãƒ³å›è»¢",
                    "description": "æ–œäº¤å›è»¢ã€æŸ”è»Ÿãªå› å­æ§‹é€ ",
                },
                {
                    "id": "equamax",
                    "name": "ã‚¤ã‚¯ã‚¢ãƒãƒƒã‚¯ã‚¹å›è»¢",
                    "description": "ç›´äº¤å›è»¢ã€varimax ã¨ quartimax ã®ä¸­é–“",
                },
            ]
        )

    return methods


@router.get("/parameters/validate")
async def validate_factor_parameters(
    n_factors: Optional[int] = Query(None, description="å› å­æ•°"),
    rotation: str = Query("varimax", description="å›è»¢æ–¹æ³•"),
    standardize: bool = Query(True, description="æ¨™æº–åŒ–"),
):
    """å› å­åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
    validation_result = {"valid": True, "warnings": [], "errors": []}

    # å› å­æ•°ã®æ¤œè¨¼
    if n_factors is not None:
        if n_factors < 1:
            validation_result["errors"].append("å› å­æ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
            validation_result["valid"] = False
        elif n_factors > 20:
            validation_result["warnings"].append(
                "å› å­æ•°ãŒå¤šã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: â‰¤10ï¼‰"
            )

    # å›è»¢æ–¹æ³•ã®æ¤œè¨¼
    if FACTOR_ANALYZER_AVAILABLE:
        valid_rotations = ["varimax", "promax", "oblimin", "quartimax", "equamax"]
    else:
        valid_rotations = ["varimax", "quartimax"]

    if rotation not in valid_rotations:
        validation_result["errors"].append(
            f"ç„¡åŠ¹ãªå›è»¢æ–¹æ³•ã§ã™ã€‚åˆ©ç”¨å¯èƒ½: {valid_rotations}"
        )
        validation_result["valid"] = False

    return validation_result


@router.get("/interpretation")
async def get_interpretation_guide():
    """å› å­åˆ†æçµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰ã‚’å–å¾—"""
    return {
        "kmo_interpretation": {
            "description": "Kaiser-Meyer-Olkiné©åˆåº¦æ¸¬åº¦",
            "ranges": {
                "0.9ä»¥ä¸Š": "å„ªç§€ - å› å­åˆ†æã«éå¸¸ã«é©ã—ã¦ã„ã‚‹",
                "0.8-0.9": "è‰¯å¥½ - å› å­åˆ†æã«é©ã—ã¦ã„ã‚‹",
                "0.7-0.8": "é©åˆ‡ - å› å­åˆ†æãŒå¯èƒ½",
                "0.6-0.7": "ä¸è‰¯ - å› å­åˆ†æã«ã¯ä¸é©åˆ‡",
                "0.6æœªæº€": "ä¸é©åˆ‡ - å› å­åˆ†æã¯æ¨å¥¨ã•ã‚Œãªã„",
            },
        },
        "bartlett_test": {
            "description": "Bartlettçƒé¢æ€§æ¤œå®š",
            "interpretation": {
                "p < 0.05": "æœ‰æ„ - å¤‰æ•°é–“ã«ç›¸é–¢ãŒã‚ã‚Šã€å› å­åˆ†æã«é©ã—ã¦ã„ã‚‹",
                "p >= 0.05": "éæœ‰æ„ - å¤‰æ•°é–“ã®ç›¸é–¢ãŒä½ãã€å› å­åˆ†æã«ä¸é©åˆ‡",
            },
        },
        "communality": {
            "description": "å…±é€šæ€§ - å› å­ã«ã‚ˆã£ã¦èª¬æ˜ã•ã‚Œã‚‹å¤‰æ•°ã®åˆ†æ•£ã®å‰²åˆ",
            "ranges": {
                "0.7ä»¥ä¸Š": "é«˜ã„ - å› å­ã«ã‚ˆã£ã¦ã‚ˆãèª¬æ˜ã•ã‚Œã‚‹",
                "0.5-0.7": "ä¸­ç¨‹åº¦ - é©åˆ‡ã«èª¬æ˜ã•ã‚Œã‚‹",
                "0.5æœªæº€": "ä½ã„ - å› å­ã«ã‚ˆã‚‹èª¬æ˜ãŒä¸ååˆ†",
            },
        },
        "factor_loadings": {
            "description": "å› å­è² è·é‡ - å¤‰æ•°ã¨å› å­ã®ç›¸é–¢ã®å¼·ã•",
            "ranges": {
                "0.7ä»¥ä¸Š": "å¼·ã„é–¢é€£",
                "0.5-0.7": "ä¸­ç¨‹åº¦ã®é–¢é€£",
                "0.3-0.5": "å¼±ã„é–¢é€£",
                "0.3æœªæº€": "ã»ã¨ã‚“ã©é–¢é€£ãªã—",
            },
        },
        "eigenvalue": {
            "description": "å›ºæœ‰å€¤ - å„å› å­ãŒèª¬æ˜ã™ã‚‹åˆ†æ•£ã®å¤§ãã•",
            "interpretation": {
                "KaiseråŸºæº–": "å›ºæœ‰å€¤1ä»¥ä¸Šã®å› å­ã‚’æ¡ç”¨",
                "ã‚¹ã‚¯ãƒªãƒ¼åŸºæº–": "ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã®æ€¥æ¿€ãªæ¸›å°‘ç‚¹ã¾ã§æ¡ç”¨",
            },
        },
    }


@router.get("/sessions/{session_id}")
async def get_factor_session_detail(
    session_id: int,
    db: Session = Depends(get_db),
):
    """å› å­åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—"""
    try:
        print(f"ğŸ“Š å› å­åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—é–‹å§‹: {session_id}")

        # FactorAnalysisAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        analyzer = FactorAnalysisAnalyzer()

        # ä¿®æ­£ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰åã§å‘¼ã³å‡ºã—
        session_detail = await analyzer.get_session_detail(session_id, db)

        print(f"ğŸ” å–å¾—ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°: {session_detail.get('success', False)}")

        if not session_detail or not session_detail.get("success"):
            error_msg = (
                session_detail.get("error", f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                if session_detail
                else f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )
            raise HTTPException(status_code=404, detail=error_msg)

        return JSONResponse(content=session_detail)

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ å› å­åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500,
            detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


# routers/factor.py ã«è¿½åŠ ã™ã‚‹é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰


@router.get("/download/{session_id}/details")
async def download_factor_details(session_id: int, db: Session = Depends(get_db)):
    """å› å­åˆ†æçµæœè©³ç´°ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        import csv
        import io
        from fastapi.responses import Response
        from models import (
            AnalysisSession,
            EigenvalueData,
            AnalysisMetadata,
            CoordinatesData,
        )

        print(f"Starting factor details download for session: {session_id}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "factor":
            raise HTTPException(
                status_code=400, detail="å› å­åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        print(f"Session found: {session.session_name}")

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata_entries = (
            db.query(AnalysisMetadata)
            .filter(AnalysisMetadata.session_id == session_id)
            .all()
        )

        # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        coordinates_data = (
            db.query(CoordinatesData)
            .filter(CoordinatesData.session_id == session_id)
            .all()
        )

        # å›ºæœ‰å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        eigenvalue_data = (
            db.query(EigenvalueData)
            .filter(EigenvalueData.session_id == session_id)
            .all()
        )

        print(
            f"Found {len(metadata_entries)} metadata entries, {len(coordinates_data)} coordinates, {len(eigenvalue_data)} eigenvalues"
        )

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"])
        writer.writerow(["é …ç›®", "å€¤"])
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³å", session.session_name])
        writer.writerow(["ãƒ•ã‚¡ã‚¤ãƒ«å", session.original_filename])
        writer.writerow(["åˆ†ææ‰‹æ³•", "å› å­åˆ†æ"])
        writer.writerow(
            ["åˆ†ææ—¥æ™‚", session.analysis_timestamp.strftime("%Y-%m-%d %H:%M:%S")]
        )
        writer.writerow(["ã‚µãƒ³ãƒ—ãƒ«æ•°", session.row_count])
        writer.writerow(["å¤‰æ•°æ•°", session.column_count])
        writer.writerow([])

        # å›ºæœ‰å€¤ã¨å¯„ä¸ç‡
        if eigenvalue_data:
            writer.writerow(["å› å­ã®å›ºæœ‰å€¤ã¨å¯„ä¸ç‡"])
            writer.writerow(["å› å­", "å›ºæœ‰å€¤", "å¯„ä¸ç‡(%)", "ç´¯ç©å¯„ä¸ç‡(%)"])

            for eigenval in sorted(eigenvalue_data, key=lambda x: x.dimension_number):
                eigenvalue = eigenval.eigenvalue if eigenval.eigenvalue else 0
                explained_variance = (
                    eigenval.explained_inertia if eigenval.explained_inertia else 0
                )
                cumulative_variance = (
                    eigenval.cumulative_inertia if eigenval.cumulative_inertia else 0
                )

                writer.writerow(
                    [
                        f"Factor{eigenval.dimension_number}",
                        f"{eigenvalue:.8f}",
                        f"{explained_variance*100:.2f}",
                        f"{cumulative_variance*100:.2f}",
                    ]
                )
            writer.writerow([])

        # å› å­è² è·é‡ï¼ˆå¤‰æ•°åº§æ¨™ï¼‰
        variable_coords = [
            coord for coord in coordinates_data if coord.point_type == "variable"
        ]
        if variable_coords:
            writer.writerow(["å› å­è² è·é‡"])
            writer.writerow(["å¤‰æ•°å", "Factor1", "Factor2", "Factor3", "å…±é€šæ€§"])
            for coord in variable_coords:
                # å…±é€šæ€§ã‚’è¨ˆç®—ï¼ˆå› å­è² è·é‡ã®äºŒä¹—å’Œï¼‰
                f1 = coord.dimension_1 if coord.dimension_1 else 0.0
                f2 = coord.dimension_2 if coord.dimension_2 else 0.0
                f3 = coord.dimension_3 if coord.dimension_3 else 0.0
                communality = f1**2 + f2**2 + f3**2

                writer.writerow(
                    [
                        coord.point_name,
                        f"{f1:.6f}",
                        f"{f2:.6f}",
                        f"{f3:.6f}",
                        f"{communality:.6f}",
                    ]
                )
            writer.writerow([])

        # å› å­å¾—ç‚¹ï¼ˆã‚µãƒ³ãƒ—ãƒ«åº§æ¨™ï¼‰
        sample_coords = [
            coord for coord in coordinates_data if coord.point_type == "observation"
        ]
        if sample_coords:
            writer.writerow(["å› å­å¾—ç‚¹"])
            writer.writerow(["ã‚µãƒ³ãƒ—ãƒ«å", "Factor1", "Factor2", "Factor3"])
            for coord in sample_coords:
                writer.writerow(
                    [
                        coord.point_name,
                        f"{coord.dimension_1:.6f}" if coord.dimension_1 else "0.000000",
                        f"{coord.dimension_2:.6f}" if coord.dimension_2 else "0.000000",
                        f"{coord.dimension_3:.6f}" if coord.dimension_3 else "0.000000",
                    ]
                )
            writer.writerow([])

        # CSVå†…å®¹ã‚’å–å¾—
        csv_content = output.getvalue()
        output.close()

        print(f"Generated CSV content length: {len(csv_content)} characters")

        # ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
        filename = f"factor_details_{session_id}.csv"

        # Responseã‚’ä½œæˆ
        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv",
            headers={"Content-Disposition": f'attachment; filename="{filename}"'},
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"è©³ç´°CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=500, detail=f"è©³ç´°CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/download/{session_id}/loadings")
async def download_factor_loadings(session_id: int, db: Session = Depends(get_db)):
    """å› å­è² è·é‡ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, CoordinatesData

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "factor":
            raise HTTPException(
                status_code=400, detail="å› å­åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        # å¤‰æ•°åº§æ¨™ãƒ‡ãƒ¼ã‚¿ï¼ˆå› å­è² è·é‡ï¼‰ã‚’å–å¾—
        loadings = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "variable",
            )
            .all()
        )

        if not loadings:
            raise HTTPException(status_code=404, detail="å› å­è² è·é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow(
            ["variable_name", "Factor1", "Factor2", "Factor3", "communality"]
        )

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for loading in loadings:
            f1 = loading.dimension_1 if loading.dimension_1 is not None else 0.0
            f2 = loading.dimension_2 if loading.dimension_2 is not None else 0.0
            f3 = loading.dimension_3 if loading.dimension_3 is not None else 0.0
            communality = f1**2 + f2**2 + f3**2

            writer.writerow([loading.point_name, f1, f2, f3, communality])

        output.seek(0)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = StreamingResponse(
            io.StringIO(output.getvalue()),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=factor_loadings_{session_id}.csv"
            },
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        print(f"å› å­è² è·é‡CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"å› å­è² è·é‡CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/download/{session_id}/scores")
async def download_factor_scores(session_id: int, db: Session = Depends(get_db)):
    """å› å­å¾—ç‚¹ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, CoordinatesData

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "factor":
            raise HTTPException(
                status_code=400, detail="å› å­åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        # ã‚µãƒ³ãƒ—ãƒ«åº§æ¨™ãƒ‡ãƒ¼ã‚¿ï¼ˆå› å­å¾—ç‚¹ï¼‰ã‚’å–å¾—
        scores = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "observation",
            )
            .all()
        )

        if not scores:
            raise HTTPException(status_code=404, detail="å› å­å¾—ç‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow(["sample_name", "Factor1", "Factor2", "Factor3"])

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for score in scores:
            writer.writerow(
                [
                    score.point_name,
                    score.dimension_1 if score.dimension_1 is not None else 0.0,
                    score.dimension_2 if score.dimension_2 is not None else 0.0,
                    score.dimension_3 if score.dimension_3 is not None else 0.0,
                ]
            )

        output.seek(0)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = StreamingResponse(
            io.StringIO(output.getvalue()),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=factor_scores_{session_id}.csv"
            },
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        print(f"å› å­å¾—ç‚¹CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"å› å­å¾—ç‚¹CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )
