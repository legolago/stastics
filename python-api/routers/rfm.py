from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Query
from fastapi.responses import JSONResponse, StreamingResponse, Response
from sqlalchemy.orm import Session
import pandas as pd
import numpy as np
import io
import csv
from typing import Optional, List
from datetime import datetime
import os
from models import get_db
from analysis.rfm import RFMAnalysisAnalyzer

router = APIRouter(prefix="/rfm", tags=["rfm"])


@router.post("/analyze-fixed")
async def analyze_rfm_fixed(
    file: UploadFile = File(...),
    session_name: str = Query(...),
    customer_id_col: str = Query("id"),
    date_col: str = Query("date"),
    amount_col: str = Query("price"),
    rfm_divisions: int = Query(3),
):
    """RFMåˆ†æï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰"""
    import os
    import json
    import io
    from datetime import datetime

    try:
        print(f"=== å®Œå…¨ä¿®æ­£ç‰ˆRFMåˆ†æé–‹å§‹ ===")

        # CSVèª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®šï¼‰
        contents = await file.read()
        csv_text = None
        encodings = ["utf-8", "shift_jis", "cp932", "euc-jp"]

        for encoding in encodings:
            try:
                csv_text = contents.decode(encoding)
                print(f"âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}")
                break
            except UnicodeDecodeError:
                continue

        if csv_text is None:
            raise ValueError("å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # DataFrameã«å¤‰æ›
        df = pd.read_csv(io.StringIO(csv_text))
        print(f"ãƒ‡ãƒ¼ã‚¿: {df.shape}")

        # RFMåˆ†æå®Ÿè¡Œ
        from analysis.rfm import RFMAnalysisAnalyzer

        analyzer = RFMAnalysisAnalyzer()

        results = analyzer.analyze(
            df=df,
            customer_id_col=customer_id_col,
            date_col=date_col,
            amount_col=amount_col,
            rfm_divisions=rfm_divisions,
        )

        # ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ
        plot_base64 = analyzer.create_plot(results, df)

        # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        save_dir = "/tmp/rfm_results"
        os.makedirs(save_dir, exist_ok=True)

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆé‡è¦ï¼šã“ã“ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¦ã„ãŸï¼‰
        customer_csv_file = f"{save_dir}/{session_name}_customers.csv"

        # CSVãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        csv_data = []
        csv_data.append(
            "customer_id,recency,frequency,monetary,rfm_score,r_score,f_score,m_score,segment"
        )

        for customer in results["customer_rfm_data"]:
            row = f"{customer['customer_id']},{customer['recency']},{customer['frequency']},{customer['monetary']},{customer['rfm_score']},{customer['r_score']},{customer['f_score']},{customer['m_score']},{customer['segment']}"
            csv_data.append(row)

        # CSVãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
        with open(customer_csv_file, "w", encoding="utf-8-sig", newline="") as f:
            f.write("\n".join(csv_data))

        print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {customer_csv_file}")
        print(f"âœ… é¡§å®¢ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(results['customer_rfm_data'])}")

        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜
        result_data = {
            "session_name": session_name,
            "analysis_type": "rfm",
            "timestamp": datetime.now().isoformat(),
            "total_customers": results["total_customers"],
            "analysis_date": results["analysis_date"],
            "customer_data": results["customer_rfm_data"],
            "segment_counts": results["segment_counts"],
            "plot_image": plot_base64,
        }

        result_file = f"{save_dir}/{session_name}_complete.json"
        with open(result_file, "w", encoding="utf-8") as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)

        return {
            "success": True,
            "session_name": session_name,
            "total_customers": results["total_customers"],
            "analysis_date": results["analysis_date"],
            "customer_data": results["customer_rfm_data"][:50],  # æœ€åˆã®50ä»¶
            "segment_counts": results["segment_counts"],
            "files": {"csv": customer_csv_file, "json": result_file},
            "download_urls": {
                "csv": f"/api/rfm/download-file/{session_name}",
                "json": f"/api/rfm/download-json/{session_name}",
            },
        }

    except Exception as e:
        print(f"âŒ å®Œå…¨ä¿®æ­£ç‰ˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze")
async def analyze_rfm(
    file: UploadFile = File(...),
    session_name: str = Query(..., description="åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å"),
    description: Optional[str] = Query(None, description="åˆ†æã®èª¬æ˜"),
    tags: Optional[str] = Query(None, description="ã‚¿ã‚°ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰"),
    user_id: str = Query("default", description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
    customer_id_col: str = Query("id", description="é¡§å®¢IDåˆ—å"),
    date_col: str = Query("date", description="æ—¥ä»˜åˆ—å"),
    amount_col: str = Query("price", description="é‡‘é¡åˆ—å"),
    analysis_date: Optional[str] = Query(None, description="åˆ†æåŸºæº–æ—¥ (YYYY-MM-DD)"),
    rfm_divisions: int = Query(3, description="RFMåˆ†å‰²æ•°", ge=3, le=5),
    use_monetary_4_divisions: bool = Query(False, description="Monetaryã‚’4åˆ†å‰²ã™ã‚‹ã‹"),
    db: Session = Depends(get_db),
):
    """RFMåˆ†æã‚’å®Ÿè¡Œ"""
    try:
        print(f"=== RFMåˆ†æAPIå‘¼ã³å‡ºã—é–‹å§‹ ===")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_name}")
        print(f"é¡§å®¢IDåˆ—: {customer_id_col}, æ—¥ä»˜åˆ—: {date_col}, é‡‘é¡åˆ—: {amount_col}")
        print(f"åˆ†æåŸºæº–æ—¥: {analysis_date}, RFMåˆ†å‰²æ•°: {rfm_divisions}")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not file.filename.endswith(".csv"):
            raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™")

        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        contents = await file.read()
        try:
            csv_text = contents.decode("utf-8")
        except UnicodeDecodeError:
            try:
                csv_text = contents.decode("shift_jis")
            except UnicodeDecodeError:
                csv_text = contents.decode("iso-8859-1")

        print(f"CSVãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:\n{csv_text[:500]}")

        # CSVã‚’DataFrameã«å¤‰æ›
        df = pd.read_csv(io.StringIO(csv_text))
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ :\n{df.head()}")
        print(f"åˆ—å: {list(df.columns)}")

        if df.empty:
            raise HTTPException(status_code=400, detail="ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")

        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_cols = [customer_id_col, date_col, amount_col]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise HTTPException(
                status_code=400,
                detail=f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}. åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}",
            )

        # åˆ†æåŸºæº–æ—¥ã®æ¤œè¨¼
        if analysis_date:
            try:
                datetime.strptime(analysis_date, "%Y-%m-%d")
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail="åˆ†æåŸºæº–æ—¥ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚YYYY-MM-DDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
                )

        # ã‚¿ã‚°å‡¦ç†
        tag_list = [tag.strip() for tag in tags.split(",")] if tags else []

        # åˆ†æå®Ÿè¡Œ
        analyzer = RFMAnalysisAnalyzer()
        response_data = analyzer.run_full_analysis(
            df=df,
            db=db,
            session_name=session_name,
            description=description,
            tags=tag_list,
            user_id=user_id,
            file=file,
            csv_text=csv_text,
            customer_id_col=customer_id_col,
            date_col=date_col,
            amount_col=amount_col,
            analysis_date=analysis_date,
            rfm_divisions=rfm_divisions,
            use_monetary_4_divisions=use_monetary_4_divisions,
        )

        print("=== RFMåˆ†æAPIå‡¦ç†å®Œäº† ===")
        return JSONResponse(content=response_data)

    except HTTPException:
        raise
    except Exception as e:
        print(f"=== RFMåˆ†æAPIå‡¦ç†ã‚¨ãƒ©ãƒ¼ ===")
        print(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500, detail=f"RFMåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/methods")
async def get_rfm_methods():
    """RFMåˆ†æã§åˆ©ç”¨å¯èƒ½ãªæ‰‹æ³•ä¸€è¦§ã‚’å–å¾—"""
    methods = {
        "rfm_divisions": [
            {
                "value": 3,
                "name": "3åˆ†å‰²",
                "description": "ä½ãƒ»ä¸­ãƒ»é«˜ã®3æ®µéšã§RFMå€¤ã‚’åˆ†å‰²",
            },
            {
                "value": 4,
                "name": "4åˆ†å‰²",
                "description": "ã‚ˆã‚Šç´°ã‹ã„4æ®µéšã§RFMå€¤ã‚’åˆ†å‰²",
            },
            {
                "value": 5,
                "name": "5åˆ†å‰²",
                "description": "æœ€ã‚‚ç´°ã‹ã„5æ®µéšã§RFMå€¤ã‚’åˆ†å‰²",
            },
        ],
        "segment_definitions": {
            "VIPé¡§å®¢": "æœ€è¿‘è³¼å…¥ã—ã€é »ç¹ã«è³¼å…¥ã—ã€é«˜é¡ãªé¡§å®¢",
            "å„ªè‰¯é¡§å®¢": "æœ€è¿‘è³¼å…¥ã—ã€é©åº¦ã«è³¼å…¥ã—ã€ã‚ã‚‹ç¨‹åº¦ã®é‡‘é¡ã‚’ä½¿ã†é¡§å®¢",
            "æ–°è¦é¡§å®¢": "æœ€è¿‘è³¼å…¥ã—ãŸãŒã€ã¾ã é »åº¦ã‚„é‡‘é¡ãŒå°‘ãªã„é¡§å®¢",
            "è¦æ³¨æ„ãƒ˜ãƒ“ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼": "è³¼å…¥é »åº¦ãƒ»é‡‘é¡ã¯é«˜ã„ãŒã€æœ€è¿‘è³¼å…¥ã—ã¦ã„ãªã„é¡§å®¢",
            "å®‰å®šé¡§å®¢": "å®šæœŸçš„ã«è³¼å…¥ã—ã¦ã„ã‚‹é¡§å®¢",
            "è¦‹è¾¼ã¿é¡§å®¢": "ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚‹é¡§å®¢",
            "é›¢è„±ã—ãŸå„ªè‰¯é¡§å®¢": "éå»ã¯å„ªè‰¯ã ã£ãŸãŒã€æœ€è¿‘è³¼å…¥ã—ã¦ã„ãªã„é¡§å®¢",
            "é›¢è„±ã—ã¤ã¤ã‚ã‚‹é¡§å®¢": "è³¼å…¥ãŒæ¸›ã£ã¦ã„ã‚‹é¡§å®¢",
            "é›¢è„±é¡§å®¢": "è³¼å…¥ã—ãªããªã£ãŸé¡§å®¢",
        },
        "required_columns": {
            "customer_id": "é¡§å®¢ã‚’è­˜åˆ¥ã™ã‚‹ãŸã‚ã®åˆ—ï¼ˆä¾‹: id, customer_idï¼‰",
            "date": "è³¼å…¥æ—¥ä»˜ã®åˆ—ï¼ˆä¾‹: date, purchase_dateï¼‰",
            "amount": "è³¼å…¥é‡‘é¡ã®åˆ—ï¼ˆä¾‹: price, amount, totalï¼‰",
        },
        "guidelines": {
            "minimum_data_period": "æœ€ä½3ãƒ¶æœˆé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¨å¥¨",
            "minimum_customers": "æœ€ä½50äººã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’æ¨å¥¨",
            "date_format": "æ—¥ä»˜ã¯ YYYY-MM-DD, YYYY/MM/DD ãªã©ã®å½¢å¼ã«å¯¾å¿œ",
            "analysis_date": "åˆ†æåŸºæº–æ—¥ã‚’æŒ‡å®šã—ãªã„å ´åˆã¯ã€ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥ã®ç¿Œæ—¥ã‚’ä½¿ç”¨",
        },
    }

    return methods


@router.get("/parameters/validate")
async def validate_rfm_parameters(
    customer_id_col: str = Query("id", description="é¡§å®¢IDåˆ—å"),
    date_col: str = Query("date", description="æ—¥ä»˜åˆ—å"),
    amount_col: str = Query("price", description="é‡‘é¡åˆ—å"),
    analysis_date: Optional[str] = Query(None, description="åˆ†æåŸºæº–æ—¥"),
    rfm_divisions: int = Query(3, description="RFMåˆ†å‰²æ•°"),
):
    """RFMåˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
    validation_result = {"valid": True, "warnings": [], "errors": []}

    # åˆ—åã®æ¤œè¨¼
    if not customer_id_col.strip():
        validation_result["errors"].append("é¡§å®¢IDåˆ—åã¯å¿…é ˆã§ã™")
        validation_result["valid"] = False

    if not date_col.strip():
        validation_result["errors"].append("æ—¥ä»˜åˆ—åã¯å¿…é ˆã§ã™")
        validation_result["valid"] = False

    if not amount_col.strip():
        validation_result["errors"].append("é‡‘é¡åˆ—åã¯å¿…é ˆã§ã™")
        validation_result["valid"] = False

    # åˆ†æåŸºæº–æ—¥ã®æ¤œè¨¼
    if analysis_date:
        try:
            datetime.strptime(analysis_date, "%Y-%m-%d")
        except ValueError:
            validation_result["errors"].append(
                "åˆ†æåŸºæº–æ—¥ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚YYYY-MM-DDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
            )
            validation_result["valid"] = False

    # RFMåˆ†å‰²æ•°ã®æ¤œè¨¼
    if rfm_divisions < 3:
        validation_result["errors"].append("RFMåˆ†å‰²æ•°ã¯3ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        validation_result["valid"] = False
    elif rfm_divisions > 5:
        validation_result["warnings"].append(
            "RFMåˆ†å‰²æ•°ãŒå¤šã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: 3-5ï¼‰"
        )

    return validation_result


@router.get("/interpretation")
async def get_interpretation_guide():
    """RFMåˆ†æçµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰ã‚’å–å¾—"""
    return {
        "rfm_metrics": {
            "recency": {
                "description": "æœ€çµ‚è³¼å…¥ã‹ã‚‰ã®çµŒéæ—¥æ•°",
                "interpretation": "å€¤ãŒå°ã•ã„ã»ã©è‰¯ã„ï¼ˆæœ€è¿‘è³¼å…¥ã—ã¦ã„ã‚‹ï¼‰",
            },
            "frequency": {
                "description": "è³¼å…¥å›æ•°",
                "interpretation": "å€¤ãŒå¤§ãã„ã»ã©è‰¯ã„ï¼ˆé »ç¹ã«è³¼å…¥ã—ã¦ã„ã‚‹ï¼‰",
            },
            "monetary": {
                "description": "è³¼å…¥é‡‘é¡åˆè¨ˆ",
                "interpretation": "å€¤ãŒå¤§ãã„ã»ã©è‰¯ã„ï¼ˆå¤šãè³¼å…¥ã—ã¦ã„ã‚‹ï¼‰",
            },
        },
        "segments": {
            "VIPé¡§å®¢": {
                "characteristics": "R=é«˜, F=é«˜, M=é«˜",
                "action": "é–¢ä¿‚ç¶­æŒã€ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚µãƒ¼ãƒ“ã‚¹æä¾›",
            },
            "å„ªè‰¯é¡§å®¢": {
                "characteristics": "R=é«˜, F=ä¸­-é«˜, M=ä¸­-é«˜",
                "action": "ã‚¢ãƒƒãƒ—ã‚»ãƒ«ã€ã‚¯ãƒ­ã‚¹ã‚»ãƒ«",
            },
            "æ–°è¦é¡§å®¢": {
                "characteristics": "R=é«˜, F=ä½, M=ä½",
                "action": "ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ãƒªãƒ†ãƒ³ã‚·ãƒ§ãƒ³å¼·åŒ–",
            },
            "è¦æ³¨æ„ãƒ˜ãƒ“ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼": {
                "characteristics": "R=ä½, F=é«˜, M=é«˜",
                "action": "ç·Šæ€¥ãƒªãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ–½ç­–",
            },
            "å®‰å®šé¡§å®¢": {
                "characteristics": "R=ä¸­, F=ä¸­, M=ä¸­",
                "action": "å®šæœŸçš„ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
            },
            "é›¢è„±é¡§å®¢": {
                "characteristics": "R=ä½, F=ä½, M=ä½",
                "action": "ã‚¦ã‚£ãƒ³ãƒãƒƒã‚¯æ–½ç­–",
            },
        },
        "score_interpretation": {
            "high_scores": "9ä»¥ä¸Š: æœ€å„ªè‰¯é¡§å®¢",
            "medium_scores": "6-8: ä¸€èˆ¬é¡§å®¢",
            "low_scores": "3-5: è¦æ”¹å–„é¡§å®¢",
        },
    }


@router.get("/sessions/{session_id}")
async def get_rfm_session_detail(
    session_id: int,
    db: Session = Depends(get_db),
):
    """RFMåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—"""
    try:
        print(f"ğŸ“Š RFMåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—é–‹å§‹: {session_id}")

        # RFMAnalysisAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        analyzer = RFMAnalysisAnalyzer()

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—
        session_detail = await analyzer.get_session_detail_async(session_id, db)

        print(f"ğŸ” å–å¾—ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°: {session_detail.get('success', False)}")

        if not session_detail or not session_detail.get("success"):
            error_msg = (
                session_detail.get("error", f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                if session_detail
                else f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )
            raise HTTPException(status_code=404, detail=error_msg)

        return JSONResponse(content=session_detail)

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ RFMåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500,
            detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/download/{session_id}/details")
async def download_rfm_details(session_id: int, db: Session = Depends(get_db)):
    """RFMåˆ†æçµæœè©³ç´°ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, AnalysisMetadata, CoordinatesData

        print(f"Starting RFM details download for session: {session_id}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "rfm":
            raise HTTPException(
                status_code=400, detail="RFMåˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        print(f"Session found: {session.session_name}")

        # é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        customer_data = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "customer",
            )
            .all()
        )

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata_entries = (
            db.query(AnalysisMetadata)
            .filter(AnalysisMetadata.session_id == session_id)
            .all()
        )

        print(
            f"Found {len(customer_data)} customers, {len(metadata_entries)} metadata entries"
        )

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"])
        writer.writerow(["é …ç›®", "å€¤"])
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³å", session.session_name])
        writer.writerow(["ãƒ•ã‚¡ã‚¤ãƒ«å", session.original_filename])
        writer.writerow(["åˆ†ææ‰‹æ³•", "RFMåˆ†æ"])
        writer.writerow(
            ["åˆ†ææ—¥æ™‚", session.analysis_timestamp.strftime("%Y-%m-%d %H:%M:%S")]
        )
        writer.writerow(["ãƒ‡ãƒ¼ã‚¿è¡Œæ•°", session.row_count])
        writer.writerow(["ç·é¡§å®¢æ•°", len(customer_data)])
        writer.writerow([])

        # RFMçµ±è¨ˆæƒ…å ±
        rfm_stats = None
        for meta in metadata_entries:
            if meta.metadata_type == "rfm_statistics":
                rfm_stats = meta.metadata_content
                break

        if rfm_stats:
            writer.writerow(["RFMçµ±è¨ˆæƒ…å ±"])

            # Recencyçµ±è¨ˆ
            writer.writerow(["Recencyçµ±è¨ˆ"])
            writer.writerow(["é …ç›®", "å€¤"])
            r_stats = rfm_stats.get("rfm_stats", {}).get("recency", {})
            writer.writerow(["å¹³å‡", f"{r_stats.get('mean', 0):.2f}"])
            writer.writerow(["æ¨™æº–åå·®", f"{r_stats.get('std', 0):.2f}"])
            writer.writerow(["æœ€å°å€¤", f"{r_stats.get('min', 0):.2f}"])
            writer.writerow(["æœ€å¤§å€¤", f"{r_stats.get('max', 0):.2f}"])
            writer.writerow([])

            # Frequencyçµ±è¨ˆ
            writer.writerow(["Frequencyçµ±è¨ˆ"])
            writer.writerow(["é …ç›®", "å€¤"])
            f_stats = rfm_stats.get("rfm_stats", {}).get("frequency", {})
            writer.writerow(["å¹³å‡", f"{f_stats.get('mean', 0):.2f}"])
            writer.writerow(["æ¨™æº–åå·®", f"{f_stats.get('std', 0):.2f}"])
            writer.writerow(["æœ€å°å€¤", f"{f_stats.get('min', 0):.2f}"])
            writer.writerow(["æœ€å¤§å€¤", f"{f_stats.get('max', 0):.2f}"])
            writer.writerow([])

            # Monetaryçµ±è¨ˆ
            writer.writerow(["Monetaryçµ±è¨ˆ"])
            writer.writerow(["é …ç›®", "å€¤"])
            m_stats = rfm_stats.get("rfm_stats", {}).get("monetary", {})
            writer.writerow(["å¹³å‡", f"{m_stats.get('mean', 0):.2f}"])
            writer.writerow(["æ¨™æº–åå·®", f"{m_stats.get('std', 0):.2f}"])
            writer.writerow(["æœ€å°å€¤", f"{m_stats.get('min', 0):.2f}"])
            writer.writerow(["æœ€å¤§å€¤", f"{m_stats.get('max', 0):.2f}"])
            writer.writerow([])

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ
            segment_counts = rfm_stats.get("segment_counts", {})
            if segment_counts:
                writer.writerow(["ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ"])
                writer.writerow(["ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ", "é¡§å®¢æ•°", "å‰²åˆ(%)"])
                total_customers = sum(segment_counts.values())
                for segment, count in segment_counts.items():
                    percentage = (
                        (count / total_customers * 100) if total_customers > 0 else 0
                    )
                    writer.writerow([segment, count, f"{percentage:.1f}"])
                writer.writerow([])

        # é¡§å®¢è©³ç´°ãƒ‡ãƒ¼ã‚¿
        writer.writerow(["é¡§å®¢è©³ç´°ãƒ‡ãƒ¼ã‚¿"])
        writer.writerow(
            [
                "é¡§å®¢ID",
                "Recency",
                "Frequency",
                "Monetary",
                "RFMã‚¹ã‚³ã‚¢",
                "Rã‚¹ã‚³ã‚¢",
                "Fã‚¹ã‚³ã‚¢",
                "Mã‚¹ã‚³ã‚¢",
                "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ",
            ]
        )

        for customer in customer_data:
            metadata = customer.metadata_json or {}
            writer.writerow(
                [
                    customer.point_name,
                    f"{customer.dimension_1:.2f}" if customer.dimension_1 else "0.00",
                    f"{customer.dimension_2:.2f}" if customer.dimension_2 else "0.00",
                    f"{customer.dimension_3:.2f}" if customer.dimension_3 else "0.00",
                    f"{customer.dimension_4:.2f}" if customer.dimension_4 else "0.00",
                    metadata.get("r_score", ""),
                    metadata.get("f_score", ""),
                    metadata.get("m_score", ""),
                    metadata.get("segment", ""),
                ]
            )

        # CSVå†…å®¹ã‚’å–å¾—
        csv_content = output.getvalue()
        output.close()

        print(f"Generated CSV content length: {len(csv_content)} characters")

        # ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
        filename = f"rfm_details_{session_id}.csv"

        # Responseã‚’ä½œæˆ
        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv",
            headers={"Content-Disposition": f'attachment; filename="{filename}"'},
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"è©³ç´°CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=500, detail=f"è©³ç´°CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/download/{session_id}/customers")
async def download_customers_csv(session_id: int, db: Session = Depends(get_db)):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰RFMé¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆmetadataä¿®æ­£ç‰ˆï¼‰"""
    try:
        from fastapi import Response
        from sqlalchemy import text
        import io
        import csv
        import json

        print(f"=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰ˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: session_id={session_id} ===")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        query = text(
            """
            SELECT 
                point_name as customer_id,
                dimension_1 as recency,
                dimension_2 as frequency, 
                dimension_3 as monetary,
                dimension_4 as rfm_score,
                metadata_json
            FROM coordinates_data 
            WHERE session_id = :session_id AND point_type = 'customer'
            ORDER BY point_name::integer
        """
        )

        result = db.execute(query, {"session_id": session_id})
        rows = result.fetchall()

        if not rows:
            raise HTTPException(
                status_code=404,
                detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
            )

        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ {len(rows)} ä»¶ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")

        # CSVå½¢å¼ã«å¤‰æ›
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆBOMã¤ãUTF-8å¯¾å¿œï¼‰
        writer.writerow(
            [
                "customer_id",
                "recency",
                "frequency",
                "monetary",
                "rfm_score",
                "r_score",
                "f_score",
                "m_score",
                "segment",
            ]
        )

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        successful_rows = 0
        for row in rows:
            try:
                # metadata_jsonã®å‡¦ç†ã‚’ä¿®æ­£
                if row.metadata_json:
                    if isinstance(row.metadata_json, dict):
                        # æ—¢ã«dictå½¢å¼ã®å ´åˆï¼ˆã‚ˆãã‚ã‚‹ã‚±ãƒ¼ã‚¹ï¼‰
                        metadata = row.metadata_json
                    elif isinstance(row.metadata_json, str):
                        # æ–‡å­—åˆ—ã®å ´åˆã®ã¿JSONãƒ‘ãƒ¼ã‚¹
                        metadata = json.loads(row.metadata_json)
                    else:
                        # ãã®ä»–ã®å ´åˆã¯ç©ºã®dict
                        metadata = {}
                        print(f"ä¸æ˜ãªmetadataå½¢å¼: {type(row.metadata_json)}")
                else:
                    metadata = {}

                writer.writerow(
                    [
                        row.customer_id,
                        round(float(row.recency), 2),
                        round(float(row.frequency), 2),
                        round(float(row.monetary), 2),
                        round(float(row.rfm_score), 2),
                        metadata.get("r_score", ""),
                        metadata.get("f_score", ""),
                        metadata.get("m_score", ""),
                        metadata.get("segment", ""),
                    ]
                )

                successful_rows += 1

            except Exception as e:
                print(f"è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆcustomer_id: {row.customer_id}ï¼‰: {e}")
                print(f"metadata_jsonå‹: {type(row.metadata_json)}")
                print(f"metadata_jsonå†…å®¹: {row.metadata_json}")
                continue

        csv_content = output.getvalue()
        output.close()

        print(f"CSVç”Ÿæˆå®Œäº†: {len(csv_content)} æ–‡å­—, æˆåŠŸè¡Œæ•°: {successful_rows}")

        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv; charset=utf-8",
            headers={
                "Content-Disposition": f'attachment; filename="rfm_customers_session_{session_id}.csv"'
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ç°¡æ˜“ç‰ˆï¼šJSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
@router.get("/session/{session_id}/customers-json")
async def get_customers_json(session_id: int, db: Session = Depends(get_db)):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’JSONã§å–å¾—ï¼ˆmetadataä¿®æ­£ç‰ˆï¼‰"""
    try:
        from sqlalchemy import text
        import json

        print(f"=== é¡§å®¢ãƒ‡ãƒ¼ã‚¿JSONå–å¾—: session_id={session_id} ===")

        query = text(
            """
            SELECT 
                point_name as customer_id,
                dimension_1 as recency,
                dimension_2 as frequency, 
                dimension_3 as monetary,
                dimension_4 as rfm_score,
                metadata_json
            FROM coordinates_data 
            WHERE session_id = :session_id AND point_type = 'customer'
            ORDER BY point_name::integer
            LIMIT 100
        """
        )

        result = db.execute(query, {"session_id": session_id})
        rows = result.fetchall()

        if not rows:
            return {
                "error": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                "customers": [],
            }

        customers = []
        for row in rows:
            try:
                # metadata_jsonã®é©åˆ‡ãªå‡¦ç†
                if row.metadata_json:
                    if isinstance(row.metadata_json, dict):
                        metadata = row.metadata_json
                    elif isinstance(row.metadata_json, str):
                        metadata = json.loads(row.metadata_json)
                    else:
                        metadata = {}
                else:
                    metadata = {}

                customers.append(
                    {
                        "customer_id": row.customer_id,
                        "recency": round(float(row.recency), 2),
                        "frequency": round(float(row.frequency), 2),
                        "monetary": round(float(row.monetary), 2),
                        "rfm_score": round(float(row.rfm_score), 2),
                        "r_score": metadata.get("r_score", ""),
                        "f_score": metadata.get("f_score", ""),
                        "m_score": metadata.get("m_score", ""),
                        "segment": metadata.get("segment", ""),
                    }
                )
            except Exception as e:
                print(f"é¡§å®¢ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆID: {row.customer_id}ï¼‰: {e}")
                continue

        print(f"é¡§å®¢ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(customers)} ä»¶")

        return {
            "session_id": session_id,
            "total_customers": len(customers),
            "customers": customers,
        }

    except Exception as e:
        print(f"âŒ é¡§å®¢JSONå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {"error": str(e), "customers": []}


@router.get("/download/{session_id}/segments")
async def download_rfm_segments(session_id: int, db: Session = Depends(get_db)):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥çµ±è¨ˆã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    try:
        from models import AnalysisSession, CoordinatesData
        import pandas as pd

        print(f"=== ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ===")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )

        if not session:
            raise HTTPException(
                status_code=404, detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )

        if session.analysis_type != "rfm":
            raise HTTPException(
                status_code=400,
                detail=f"RFMåˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {session.analysis_type}",
            )

        # é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        customers = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "customer",
            )
            .all()
        )

        if not customers:
            raise HTTPException(status_code=404, detail="é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # DataFrameã«å¤‰æ›
        data_list = []
        for customer in customers:
            metadata = customer.metadata_json or {}
            data_list.append(
                {
                    "customer_id": customer.point_name,
                    "recency": customer.dimension_1 or 0,
                    "frequency": customer.dimension_2 or 0,
                    "monetary": customer.dimension_3 or 0,
                    "rfm_score": customer.dimension_4 or 0,
                    "segment": metadata.get("segment", "ä¸æ˜"),
                }
            )

        df = pd.DataFrame(data_list)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥çµ±è¨ˆã‚’è¨ˆç®—
        segment_stats = (
            df.groupby("segment")
            .agg(
                {
                    "customer_id": "count",
                    "recency": "mean",
                    "frequency": "mean",
                    "monetary": "mean",
                    "rfm_score": "mean",
                }
            )
            .round(2)
        )

        # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’è¿½åŠ 
        total_customers = len(df)
        segment_stats["percentage"] = (
            segment_stats["customer_id"] / total_customers * 100
        ).round(1)

        # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
        segment_stats.columns = [
            "customer_count",
            "avg_recency",
            "avg_frequency",
            "avg_monetary",
            "avg_rfm_score",
            "percentage",
        ]

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ—ã«å¤‰æ›
        segment_stats = segment_stats.reset_index()
        segment_stats.columns = [
            "segment",
            "customer_count",
            "avg_recency",
            "avg_frequency",
            "avg_monetary",
            "avg_rfm_score",
            "percentage",
        ]

        # CSVã¨ã—ã¦å‡ºåŠ›
        csv_content = segment_stats.to_csv(index=False, encoding="utf-8")
        print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆCSVç”Ÿæˆå®Œäº†: {len(segment_stats)} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

        filename = f"rfm_segments_{session_id}.csv"
        csv_bytes = csv_content.encode("utf-8-sig")

        return Response(
            content=csv_bytes,
            media_type="text/csv; charset=utf-8",
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"',
                "Content-Type": "text/csv; charset=utf-8",
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆCSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500,
            detail=f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆCSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/debug/session/{session_id}/data")
async def debug_session_coordinates(session_id: int, db: Session = Depends(get_db)):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«è¡¨ç¤º"""
    try:
        from models import CoordinatesData

        coordinates = (
            db.query(CoordinatesData)
            .filter(CoordinatesData.session_id == session_id)
            .limit(10)
            .all()
        )  # æœ€åˆã®10ä»¶ã®ã¿

        result = []
        for coord in coordinates:
            result.append(
                {
                    "point_name": coord.point_name,
                    "point_type": coord.point_type,
                    "dimensions": [
                        coord.dimension_1,
                        coord.dimension_2,
                        coord.dimension_3,
                        coord.dimension_4,
                    ],
                    "metadata": coord.metadata_json,
                }
            )

        return {
            "session_id": session_id,
            "total_count": db.query(CoordinatesData)
            .filter(CoordinatesData.session_id == session_id)
            .count(),
            "customer_count": db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "customer",
            )
            .count(),
            "sample_data": result,
        }

    except Exception as e:
        return {"error": str(e)}


# routers/rfm.py ã«è¿½åŠ ã™ã‚‹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ


# ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šmetadata_jsonã®å†…å®¹ã‚’è©³ã—ãèª¿æŸ»
@router.get("/debug/session/{session_id}/metadata-sample")
async def debug_metadata_sample(session_id: int, db: Session = Depends(get_db)):
    """metadata_jsonã®å†…å®¹ã‚’ã‚µãƒ³ãƒ—ãƒ«èª¿æŸ»"""
    try:
        from sqlalchemy import text

        query = text(
            """
            SELECT 
                point_name as customer_id,
                metadata_json
            FROM coordinates_data 
            WHERE session_id = :session_id AND point_type = 'customer'
            ORDER BY point_name::integer
            LIMIT 5
        """
        )

        result = db.execute(query, {"session_id": session_id})
        rows = result.fetchall()

        samples = []
        for row in rows:
            samples.append(
                {
                    "customer_id": row.customer_id,
                    "metadata_type": str(type(row.metadata_json)),
                    "metadata_content": str(row.metadata_json)[:200],  # æœ€åˆã®200æ–‡å­—
                    "is_dict": isinstance(row.metadata_json, dict),
                    "is_string": isinstance(row.metadata_json, str),
                }
            )

        return {"session_id": session_id, "samples": samples}

    except Exception as e:
        return {"error": str(e)}


# ç°¡æ˜“ç‰ˆï¼šåŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§CSVã‚’ç”Ÿæˆ
@router.get("/download/{session_id}/customers-simple")
async def download_customers_simple_csv(session_id: int, db: Session = Depends(get_db)):
    """ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆmetadataãªã—ï¼‰"""
    try:
        from fastapi import Response
        from sqlalchemy import text
        import io
        import csv

        print(f"=== ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: session_id={session_id} ===")

        query = text(
            """
            SELECT 
                point_name as customer_id,
                dimension_1 as recency,
                dimension_2 as frequency, 
                dimension_3 as monetary,
                dimension_4 as rfm_score
            FROM coordinates_data 
            WHERE session_id = :session_id AND point_type = 'customer'
            ORDER BY point_name::integer
        """
        )

        result = db.execute(query, {"session_id": session_id})
        rows = result.fetchall()

        if not rows:
            raise HTTPException(
                status_code=404,
                detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
            )

        # CSVå½¢å¼ã«å¤‰æ›
        output = io.StringIO()
        writer = csv.writer(output)

        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow(
            ["customer_id", "recency", "frequency", "monetary", "rfm_score"]
        )

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for row in rows:
            writer.writerow(
                [
                    row.customer_id,
                    round(float(row.recency), 2),
                    round(float(row.frequency), 2),
                    round(float(row.monetary), 2),
                    round(float(row.rfm_score), 2),
                ]
            )

        csv_content = output.getvalue()
        output.close()

        print(f"ã‚·ãƒ³ãƒ—ãƒ«CSVç”Ÿæˆå®Œäº†: {len(csv_content)} æ–‡å­—, {len(rows)} è¡Œ")

        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv; charset=utf-8",
            headers={
                "Content-Disposition": f'attachment; filename="rfm_customers_simple_{session_id}.csv"'
            },
        )

    except Exception as e:
        print(f"âŒ ã‚·ãƒ³ãƒ—ãƒ«CSVã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
