from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Query
from fastapi.responses import JSONResponse, StreamingResponse, Response
from sqlalchemy.orm import Session
import pandas as pd
import numpy as np
import io
import csv
from typing import Optional, List
from datetime import datetime
import os
from models import get_db
from analysis.rfm import RFMAnalysisAnalyzer

router = APIRouter(prefix="/rfm", tags=["rfm"])


@router.post("/analyze")
async def analyze_rfm(
    file: UploadFile = File(...),
    session_name: str = Query(..., description="åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å"),
    description: Optional[str] = Query(None, description="åˆ†æã®èª¬æ˜"),
    tags: Optional[str] = Query(None, description="ã‚¿ã‚°ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰"),
    user_id: str = Query("default", description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
    customer_id_col: str = Query("id", description="é¡§å®¢IDåˆ—å"),
    date_col: str = Query("date", description="æ—¥ä»˜åˆ—å"),
    amount_col: str = Query("price", description="é‡‘é¡åˆ—å"),
    analysis_date: Optional[str] = Query(None, description="åˆ†æåŸºæº–æ—¥ (YYYY-MM-DD)"),
    rfm_divisions: int = Query(3, description="RFMåˆ†å‰²æ•°", ge=3, le=5),
    use_monetary_4_divisions: bool = Query(False, description="Monetaryã‚’4åˆ†å‰²ã™ã‚‹ã‹"),
    db: Session = Depends(get_db),
):
    """RFMåˆ†æã‚’å®Ÿè¡Œ"""
    try:
        print(f"=== RFMåˆ†æAPIå‘¼ã³å‡ºã—é–‹å§‹ ===")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_name}")
        print(f"é¡§å®¢IDåˆ—: {customer_id_col}, æ—¥ä»˜åˆ—: {date_col}, é‡‘é¡åˆ—: {amount_col}")
        print(f"åˆ†æåŸºæº–æ—¥: {analysis_date}, RFMåˆ†å‰²æ•°: {rfm_divisions}")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not file.filename.endswith(".csv"):
            raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™")

        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®šï¼‰
        contents = await file.read()
        csv_text = None
        encodings = ["utf-8", "shift_jis", "cp932", "euc-jp", "iso-8859-1"]

        for encoding in encodings:
            try:
                csv_text = contents.decode(encoding)
                print(f"âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}")
                break
            except UnicodeDecodeError:
                continue

        if csv_text is None:
            raise HTTPException(status_code=400, detail="å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        print(f"CSVãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:\n{csv_text[:500]}")

        # CSVã‚’DataFrameã«å¤‰æ›
        df = pd.read_csv(io.StringIO(csv_text))
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ :\n{df.head()}")
        print(f"åˆ—å: {list(df.columns)}")

        if df.empty:
            raise HTTPException(status_code=400, detail="ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")

        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_cols = [customer_id_col, date_col, amount_col]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise HTTPException(
                status_code=400,
                detail=f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}. åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(df.columns)}",
            )

        # åˆ†æåŸºæº–æ—¥ã®æ¤œè¨¼
        if analysis_date:
            try:
                datetime.strptime(analysis_date, "%Y-%m-%d")
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail="åˆ†æåŸºæº–æ—¥ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚YYYY-MM-DDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
                )

        # ã‚¿ã‚°å‡¦ç†
        tag_list = [tag.strip() for tag in tags.split(",")] if tags else []

        # åˆ†æå®Ÿè¡Œ
        analyzer = RFMAnalysisAnalyzer()
        response_data = analyzer.run_full_analysis(
            df=df,
            db=db,
            session_name=session_name,
            description=description,
            tags=tag_list,
            user_id=user_id,
            file=file,
            csv_text=csv_text,
            customer_id_col=customer_id_col,
            date_col=date_col,
            amount_col=amount_col,
            analysis_date=analysis_date,
            rfm_divisions=rfm_divisions,
            use_monetary_4_divisions=use_monetary_4_divisions,
        )

        print("=== RFMåˆ†æAPIå‡¦ç†å®Œäº† ===")
        return JSONResponse(content=response_data)

    except HTTPException:
        raise
    except Exception as e:
        print(f"=== RFMåˆ†æAPIå‡¦ç†ã‚¨ãƒ©ãƒ¼ ===")
        print(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500, detail=f"RFMåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/methods")
async def get_rfm_methods():
    """RFMåˆ†æã§åˆ©ç”¨å¯èƒ½ãªæ‰‹æ³•ä¸€è¦§ã‚’å–å¾—"""
    methods = {
        "rfm_divisions": [
            {
                "value": 3,
                "name": "3åˆ†å‰²",
                "description": "ä½ãƒ»ä¸­ãƒ»é«˜ã®3æ®µéšã§RFMå€¤ã‚’åˆ†å‰²",
            },
            {
                "value": 4,
                "name": "4åˆ†å‰²",
                "description": "ã‚ˆã‚Šç´°ã‹ã„4æ®µéšã§RFMå€¤ã‚’åˆ†å‰²",
            },
            {
                "value": 5,
                "name": "5åˆ†å‰²",
                "description": "æœ€ã‚‚ç´°ã‹ã„5æ®µéšã§RFMå€¤ã‚’åˆ†å‰²",
            },
        ],
        "segment_definitions": {
            "VIPé¡§å®¢": "æœ€è¿‘è³¼å…¥ã—ã€é »ç¹ã«è³¼å…¥ã—ã€é«˜é¡ãªé¡§å®¢",
            "å„ªè‰¯é¡§å®¢": "æœ€è¿‘è³¼å…¥ã—ã€é©åº¦ã«è³¼å…¥ã—ã€ã‚ã‚‹ç¨‹åº¦ã®é‡‘é¡ã‚’ä½¿ã†é¡§å®¢",
            "æ–°è¦é¡§å®¢": "æœ€è¿‘è³¼å…¥ã—ãŸãŒã€ã¾ã é »åº¦ã‚„é‡‘é¡ãŒå°‘ãªã„é¡§å®¢",
            "è¦æ³¨æ„ãƒ˜ãƒ“ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼": "è³¼å…¥é »åº¦ãƒ»é‡‘é¡ã¯é«˜ã„ãŒã€æœ€è¿‘è³¼å…¥ã—ã¦ã„ãªã„é¡§å®¢",
            "å®‰å®šé¡§å®¢": "å®šæœŸçš„ã«è³¼å…¥ã—ã¦ã„ã‚‹é¡§å®¢",
            "è¦‹è¾¼ã¿é¡§å®¢": "ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚‹é¡§å®¢",
            "é›¢è„±ã—ãŸå„ªè‰¯é¡§å®¢": "éå»ã¯å„ªè‰¯ã ã£ãŸãŒã€æœ€è¿‘è³¼å…¥ã—ã¦ã„ãªã„é¡§å®¢",
            "é›¢è„±ã—ã¤ã¤ã‚ã‚‹é¡§å®¢": "è³¼å…¥ãŒæ¸›ã£ã¦ã„ã‚‹é¡§å®¢",
            "é›¢è„±é¡§å®¢": "è³¼å…¥ã—ãªããªã£ãŸé¡§å®¢",
        },
        "required_columns": {
            "customer_id": "é¡§å®¢ã‚’è­˜åˆ¥ã™ã‚‹ãŸã‚ã®åˆ—ï¼ˆä¾‹: id, customer_idï¼‰",
            "date": "è³¼å…¥æ—¥ä»˜ã®åˆ—ï¼ˆä¾‹: date, purchase_dateï¼‰",
            "amount": "è³¼å…¥é‡‘é¡ã®åˆ—ï¼ˆä¾‹: price, amount, totalï¼‰",
        },
        "guidelines": {
            "minimum_data_period": "æœ€ä½3ãƒ¶æœˆé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¨å¥¨",
            "minimum_customers": "æœ€ä½50äººã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’æ¨å¥¨",
            "date_format": "æ—¥ä»˜ã¯ YYYY-MM-DD, YYYY/MM/DD ãªã©ã®å½¢å¼ã«å¯¾å¿œ",
            "analysis_date": "åˆ†æåŸºæº–æ—¥ã‚’æŒ‡å®šã—ãªã„å ´åˆã¯ã€ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥ã®ç¿Œæ—¥ã‚’ä½¿ç”¨",
        },
    }

    return methods


@router.get("/parameters/validate")
async def validate_rfm_parameters(
    customer_id_col: str = Query("id", description="é¡§å®¢IDåˆ—å"),
    date_col: str = Query("date", description="æ—¥ä»˜åˆ—å"),
    amount_col: str = Query("price", description="é‡‘é¡åˆ—å"),
    analysis_date: Optional[str] = Query(None, description="åˆ†æåŸºæº–æ—¥"),
    rfm_divisions: int = Query(3, description="RFMåˆ†å‰²æ•°"),
):
    """RFMåˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
    validation_result = {"valid": True, "warnings": [], "errors": []}

    # åˆ—åã®æ¤œè¨¼
    if not customer_id_col.strip():
        validation_result["errors"].append("é¡§å®¢IDåˆ—åã¯å¿…é ˆã§ã™")
        validation_result["valid"] = False

    if not date_col.strip():
        validation_result["errors"].append("æ—¥ä»˜åˆ—åã¯å¿…é ˆã§ã™")
        validation_result["valid"] = False

    if not amount_col.strip():
        validation_result["errors"].append("é‡‘é¡åˆ—åã¯å¿…é ˆã§ã™")
        validation_result["valid"] = False

    # åˆ†æåŸºæº–æ—¥ã®æ¤œè¨¼
    if analysis_date:
        try:
            datetime.strptime(analysis_date, "%Y-%m-%d")
        except ValueError:
            validation_result["errors"].append(
                "åˆ†æåŸºæº–æ—¥ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚YYYY-MM-DDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
            )
            validation_result["valid"] = False

    # RFMåˆ†å‰²æ•°ã®æ¤œè¨¼
    if rfm_divisions < 3:
        validation_result["errors"].append("RFMåˆ†å‰²æ•°ã¯3ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        validation_result["valid"] = False
    elif rfm_divisions > 5:
        validation_result["warnings"].append(
            "RFMåˆ†å‰²æ•°ãŒå¤šã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: 3-5ï¼‰"
        )

    return validation_result


@router.get("/interpretation")
async def get_interpretation_guide():
    """RFMåˆ†æçµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰ã‚’å–å¾—"""
    return {
        "rfm_metrics": {
            "recency": {
                "description": "æœ€çµ‚è³¼å…¥ã‹ã‚‰ã®çµŒéæ—¥æ•°",
                "interpretation": "å€¤ãŒå°ã•ã„ã»ã©è‰¯ã„ï¼ˆæœ€è¿‘è³¼å…¥ã—ã¦ã„ã‚‹ï¼‰",
            },
            "frequency": {
                "description": "è³¼å…¥å›æ•°",
                "interpretation": "å€¤ãŒå¤§ãã„ã»ã©è‰¯ã„ï¼ˆé »ç¹ã«è³¼å…¥ã—ã¦ã„ã‚‹ï¼‰",
            },
            "monetary": {
                "description": "è³¼å…¥é‡‘é¡åˆè¨ˆ",
                "interpretation": "å€¤ãŒå¤§ãã„ã»ã©è‰¯ã„ï¼ˆå¤šãè³¼å…¥ã—ã¦ã„ã‚‹ï¼‰",
            },
        },
        "segments": {
            "VIPé¡§å®¢": {
                "characteristics": "R=é«˜, F=é«˜, M=é«˜",
                "action": "é–¢ä¿‚ç¶­æŒã€ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚µãƒ¼ãƒ“ã‚¹æä¾›",
            },
            "å„ªè‰¯é¡§å®¢": {
                "characteristics": "R=é«˜, F=ä¸­-é«˜, M=ä¸­-é«˜",
                "action": "ã‚¢ãƒƒãƒ—ã‚»ãƒ«ã€ã‚¯ãƒ­ã‚¹ã‚»ãƒ«",
            },
            "æ–°è¦é¡§å®¢": {
                "characteristics": "R=é«˜, F=ä½, M=ä½",
                "action": "ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ãƒªãƒ†ãƒ³ã‚·ãƒ§ãƒ³å¼·åŒ–",
            },
            "è¦æ³¨æ„ãƒ˜ãƒ“ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼": {
                "characteristics": "R=ä½, F=é«˜, M=é«˜",
                "action": "ç·Šæ€¥ãƒªãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ–½ç­–",
            },
            "å®‰å®šé¡§å®¢": {
                "characteristics": "R=ä¸­, F=ä¸­, M=ä¸­",
                "action": "å®šæœŸçš„ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
            },
            "é›¢è„±é¡§å®¢": {
                "characteristics": "R=ä½, F=ä½, M=ä½",
                "action": "ã‚¦ã‚£ãƒ³ãƒãƒƒã‚¯æ–½ç­–",
            },
        },
        "score_interpretation": {
            "high_scores": "9ä»¥ä¸Š: æœ€å„ªè‰¯é¡§å®¢",
            "medium_scores": "6-8: ä¸€èˆ¬é¡§å®¢",
            "low_scores": "3-5: è¦æ”¹å–„é¡§å®¢",
        },
    }


@router.get("/sessions/{session_id}")
async def get_rfm_session_detail(
    session_id: int,
    db: Session = Depends(get_db),
):
    """RFMåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—"""
    try:
        print(f"ğŸ“Š RFMåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—é–‹å§‹: {session_id}")

        # RFMAnalysisAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        analyzer = RFMAnalysisAnalyzer()

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—
        session_detail = await analyzer.get_session_detail(session_id, db)

        print(f"ğŸ” å–å¾—ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°: {session_detail.get('success', False)}")

        if not session_detail or not session_detail.get("success"):
            error_msg = (
                session_detail.get("error", f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                if session_detail
                else f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )
            raise HTTPException(status_code=404, detail=error_msg)

        return JSONResponse(content=session_detail)

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ RFMåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500,
            detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/download/{session_id}/details")
async def download_rfm_details(session_id: int, db: Session = Depends(get_db)):
    """RFMåˆ†æçµæœè©³ç´°ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, AnalysisMetadata, CoordinatesData

        print(f"Starting RFM details download for session: {session_id}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "rfm":
            raise HTTPException(
                status_code=400, detail="RFMåˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        print(f"Session found: {session.session_name}")

        # é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        customer_data = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "customer",
            )
            .all()
        )

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata_entries = (
            db.query(AnalysisMetadata)
            .filter(AnalysisMetadata.session_id == session_id)
            .all()
        )

        print(
            f"Found {len(customer_data)} customers, {len(metadata_entries)} metadata entries"
        )

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"])
        writer.writerow(["é …ç›®", "å€¤"])
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³å", session.session_name])
        writer.writerow(["ãƒ•ã‚¡ã‚¤ãƒ«å", session.original_filename])
        writer.writerow(["åˆ†ææ‰‹æ³•", "RFMåˆ†æ"])
        writer.writerow(
            ["åˆ†ææ—¥æ™‚", session.analysis_timestamp.strftime("%Y-%m-%d %H:%M:%S")]
        )
        writer.writerow(["ãƒ‡ãƒ¼ã‚¿è¡Œæ•°", session.row_count])
        writer.writerow(["ç·é¡§å®¢æ•°", len(customer_data)])
        writer.writerow([])

        # RFMçµ±è¨ˆæƒ…å ±
        rfm_stats = None
        for meta in metadata_entries:
            if meta.metadata_type == "rfm_statistics":
                rfm_stats = meta.metadata_content
                break

        if rfm_stats:
            writer.writerow(["RFMçµ±è¨ˆæƒ…å ±"])

            # Recencyçµ±è¨ˆ
            writer.writerow(["Recencyçµ±è¨ˆ"])
            writer.writerow(["é …ç›®", "å€¤"])
            r_stats = rfm_stats.get("rfm_stats", {}).get("recency", {})
            writer.writerow(["å¹³å‡", f"{r_stats.get('mean', 0):.2f}"])
            writer.writerow(["æ¨™æº–åå·®", f"{r_stats.get('std', 0):.2f}"])
            writer.writerow(["æœ€å°å€¤", f"{r_stats.get('min', 0):.2f}"])
            writer.writerow(["æœ€å¤§å€¤", f"{r_stats.get('max', 0):.2f}"])
            writer.writerow([])

            # Frequencyçµ±è¨ˆ
            writer.writerow(["Frequencyçµ±è¨ˆ"])
            writer.writerow(["é …ç›®", "å€¤"])
            f_stats = rfm_stats.get("rfm_stats", {}).get("frequency", {})
            writer.writerow(["å¹³å‡", f"{f_stats.get('mean', 0):.2f}"])
            writer.writerow(["æ¨™æº–åå·®", f"{f_stats.get('std', 0):.2f}"])
            writer.writerow(["æœ€å°å€¤", f"{f_stats.get('min', 0):.2f}"])
            writer.writerow(["æœ€å¤§å€¤", f"{f_stats.get('max', 0):.2f}"])
            writer.writerow([])

            # Monetaryçµ±è¨ˆ
            writer.writerow(["Monetaryçµ±è¨ˆ"])
            writer.writerow(["é …ç›®", "å€¤"])
            m_stats = rfm_stats.get("rfm_stats", {}).get("monetary", {})
            writer.writerow(["å¹³å‡", f"{m_stats.get('mean', 0):.2f}"])
            writer.writerow(["æ¨™æº–åå·®", f"{m_stats.get('std', 0):.2f}"])
            writer.writerow(["æœ€å°å€¤", f"{m_stats.get('min', 0):.2f}"])
            writer.writerow(["æœ€å¤§å€¤", f"{m_stats.get('max', 0):.2f}"])
            writer.writerow([])

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ
            segment_counts = rfm_stats.get("segment_counts", {})
            if segment_counts:
                writer.writerow(["ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ"])
                writer.writerow(["ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ", "é¡§å®¢æ•°", "å‰²åˆ(%)"])
                total_customers = sum(segment_counts.values())
                for segment, count in segment_counts.items():
                    percentage = (
                        (count / total_customers * 100) if total_customers > 0 else 0
                    )
                    writer.writerow([segment, count, f"{percentage:.1f}"])
                writer.writerow([])

        # é¡§å®¢è©³ç´°ãƒ‡ãƒ¼ã‚¿
        writer.writerow(["é¡§å®¢è©³ç´°ãƒ‡ãƒ¼ã‚¿"])
        writer.writerow(
            [
                "é¡§å®¢ID",
                "Recency",
                "Frequency",
                "Monetary",
                "RFMã‚¹ã‚³ã‚¢",
                "Rã‚¹ã‚³ã‚¢",
                "Fã‚¹ã‚³ã‚¢",
                "Mã‚¹ã‚³ã‚¢",
                "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ",
            ]
        )

        for customer in customer_data:
            metadata = customer.metadata_json or {}
            writer.writerow(
                [
                    customer.point_name,
                    f"{customer.dimension_1:.2f}" if customer.dimension_1 else "0.00",
                    f"{customer.dimension_2:.2f}" if customer.dimension_2 else "0.00",
                    f"{customer.dimension_3:.2f}" if customer.dimension_3 else "0.00",
                    f"{customer.dimension_4:.2f}" if customer.dimension_4 else "0.00",
                    metadata.get("r_score", ""),
                    metadata.get("f_score", ""),
                    metadata.get("m_score", ""),
                    metadata.get("segment", ""),
                ]
            )

        # CSVå†…å®¹ã‚’å–å¾—
        csv_content = output.getvalue()
        output.close()

        print(f"Generated CSV content length: {len(csv_content)} characters")

        # ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
        filename = f"rfm_details_{session_id}.csv"

        # Responseã‚’ä½œæˆ
        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv",
            headers={"Content-Disposition": f'attachment; filename="{filename}"'},
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"è©³ç´°CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500, detail=f"è©³ç´°CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/download/{session_id}/customers")
async def download_customers_csv(session_id: int, db: Session = Depends(get_db)):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰RFMé¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from fastapi import Response
        from sqlalchemy import text
        import io
        import csv
        import json

        print(f"=== é¡§å®¢ãƒ‡ãƒ¼ã‚¿CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: session_id={session_id} ===")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        query = text(
            """
            SELECT 
                point_name as customer_id,
                dimension_1 as recency,
                dimension_2 as frequency, 
                dimension_3 as monetary,
                dimension_4 as rfm_score,
                metadata_json
            FROM coordinates_data 
            WHERE session_id = :session_id AND point_type = 'customer'
            ORDER BY point_name::integer
        """
        )

        result = db.execute(query, {"session_id": session_id})
        rows = result.fetchall()

        if not rows:
            raise HTTPException(
                status_code=404,
                detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
            )

        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ {len(rows)} ä»¶ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")

        # CSVå½¢å¼ã«å¤‰æ›
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆBOMã¤ãUTF-8å¯¾å¿œï¼‰
        writer.writerow(
            [
                "customer_id",
                "recency",
                "frequency",
                "monetary",
                "rfm_score",
                "r_score",
                "f_score",
                "m_score",
                "segment",
            ]
        )

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        successful_rows = 0
        for row in rows:
            try:
                # metadata_jsonã®å‡¦ç†
                if row.metadata_json:
                    if isinstance(row.metadata_json, dict):
                        metadata = row.metadata_json
                    elif isinstance(row.metadata_json, str):
                        metadata = json.loads(row.metadata_json)
                    else:
                        metadata = {}
                else:
                    metadata = {}

                writer.writerow(
                    [
                        row.customer_id,
                        round(float(row.recency), 2),
                        round(float(row.frequency), 2),
                        round(float(row.monetary), 2),
                        round(float(row.rfm_score), 2),
                        metadata.get("r_score", ""),
                        metadata.get("f_score", ""),
                        metadata.get("m_score", ""),
                        metadata.get("segment", ""),
                    ]
                )

                successful_rows += 1

            except Exception as e:
                print(f"è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆcustomer_id: {row.customer_id}ï¼‰: {e}")
                continue

        csv_content = output.getvalue()
        output.close()

        print(f"CSVç”Ÿæˆå®Œäº†: {len(csv_content)} æ–‡å­—, æˆåŠŸè¡Œæ•°: {successful_rows}")

        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv; charset=utf-8",
            headers={
                "Content-Disposition": f'attachment; filename="rfm_customers_session_{session_id}.csv"'
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/download/{session_id}/segments")
async def download_rfm_segments(session_id: int, db: Session = Depends(get_db)):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥çµ±è¨ˆã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, CoordinatesData
        import pandas as pd

        print(f"=== ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ===")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )

        if not session:
            raise HTTPException(
                status_code=404, detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )

        if session.analysis_type != "rfm":
            raise HTTPException(
                status_code=400,
                detail=f"RFMåˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {session.analysis_type}",
            )

        # é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        customers = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "customer",
            )
            .all()
        )

        if not customers:
            raise HTTPException(status_code=404, detail="é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # DataFrameã«å¤‰æ›
        data_list = []
        for customer in customers:
            metadata = customer.metadata_json or {}
            data_list.append(
                {
                    "customer_id": customer.point_name,
                    "recency": customer.dimension_1 or 0,
                    "frequency": customer.dimension_2 or 0,
                    "monetary": customer.dimension_3 or 0,
                    "rfm_score": customer.dimension_4 or 0,
                    "segment": metadata.get("segment", "ä¸æ˜"),
                }
            )

        df = pd.DataFrame(data_list)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥çµ±è¨ˆã‚’è¨ˆç®—
        segment_stats = (
            df.groupby("segment")
            .agg(
                {
                    "customer_id": "count",
                    "recency": "mean",
                    "frequency": "mean",
                    "monetary": "mean",
                    "rfm_score": "mean",
                }
            )
            .round(2)
        )

        # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’è¿½åŠ 
        total_customers = len(df)
        segment_stats["percentage"] = (
            segment_stats["customer_id"] / total_customers * 100
        ).round(1)

        # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
        segment_stats.columns = [
            "customer_count",
            "avg_recency",
            "avg_frequency",
            "avg_monetary",
            "avg_rfm_score",
            "percentage",
        ]

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ—ã«å¤‰æ›
        segment_stats = segment_stats.reset_index()
        segment_stats.columns = [
            "segment",
            "customer_count",
            "avg_recency",
            "avg_frequency",
            "avg_monetary",
            "avg_rfm_score",
            "percentage",
        ]

        # CSVã¨ã—ã¦å‡ºåŠ›
        csv_content = segment_stats.to_csv(index=False, encoding="utf-8")
        print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆCSVç”Ÿæˆå®Œäº†: {len(segment_stats)} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

        filename = f"rfm_segments_{session_id}.csv"
        csv_bytes = csv_content.encode("utf-8-sig")

        return Response(
            content=csv_bytes,
            media_type="text/csv; charset=utf-8",
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"',
                "Content-Type": "text/csv; charset=utf-8",
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆCSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500,
            detail=f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµ±è¨ˆCSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )