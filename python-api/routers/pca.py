from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Query
from fastapi.responses import JSONResponse, StreamingResponse, Response
from sqlalchemy.orm import Session
import pandas as pd
import numpy as np
import io
import csv
from typing import Optional, List

from models import get_db
from analysis.pca import PCAAnalyzer

router = APIRouter(prefix="/pca", tags=["pca"])


@router.post("/analyze")
async def analyze_pca(
    file: UploadFile = File(...),
    session_name: str = Query(..., description="åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å"),
    description: Optional[str] = Query(None, description="åˆ†æã®èª¬æ˜"),
    tags: Optional[str] = Query(None, description="ã‚¿ã‚°ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰"),
    user_id: str = Query("default", description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
    n_components: int = Query(2, description="ä¸»æˆåˆ†æ•°"),
    standardize: bool = Query(True, description="æ¨™æº–åŒ–ã®å®Ÿè¡Œ"),
    db: Session = Depends(get_db),
):
    """ä¸»æˆåˆ†åˆ†æã‚’å®Ÿè¡Œ"""
    try:
        print(f"=== PCA APIå‘¼ã³å‡ºã—é–‹å§‹ ===")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_name}")
        print(f"ä¸»æˆåˆ†æ•°: {n_components}")
        print(f"æ¨™æº–åŒ–: {standardize}")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not file.filename.endswith(".csv"):
            raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™")

        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        contents = await file.read()
        try:
            csv_text = contents.decode("utf-8")
        except UnicodeDecodeError:
            csv_text = contents.decode("shift_jis")

        print(f"CSVãƒ†ã‚­ã‚¹ãƒˆ:\n{csv_text}")

        df = pd.read_csv(io.StringIO(csv_text), index_col=0)
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ :\n{df}")

        if df.empty:
            raise HTTPException(status_code=400, detail="ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡º
        numeric_df = df.select_dtypes(include=[np.number])
        if numeric_df.empty:
            raise HTTPException(
                status_code=400,
                detail="æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä¸»æˆåˆ†åˆ†æã«ã¯æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚",
            )

        # æ¬ æå€¤ã®å‡¦ç†
        if numeric_df.isnull().any().any():
            numeric_df = numeric_df.dropna()
            if numeric_df.empty:
                raise HTTPException(
                    status_code=400,
                    detail="æ¬ æå€¤ã‚’é™¤å»ã—ãŸçµæœã€ãƒ‡ãƒ¼ã‚¿ãŒç©ºã«ãªã‚Šã¾ã—ãŸã€‚",
                )

        # ã‚¿ã‚°å‡¦ç†
        tag_list = [tag.strip() for tag in tags.split(",")] if tags else []

        # åˆ†æå®Ÿè¡Œï¼ˆBaseAnalyzerã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ï¼‰
        analyzer = PCAAnalyzer()
        response_data = analyzer.run_full_analysis(
            df=numeric_df,
            db=db,
            session_name=session_name,
            description=description,
            tags=tag_list,
            user_id=user_id,
            file=file,
            csv_text=csv_text,
            n_components=n_components,
            standardize=standardize,
        )

        print("=== PCA APIå‡¦ç†å®Œäº† ===")
        return JSONResponse(content=response_data)

    except HTTPException:
        raise
    except Exception as e:
        print(f"=== PCA APIå‡¦ç†ã‚¨ãƒ©ãƒ¼ ===")
        print(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500, detail=f"PCAåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/methods")
async def get_pca_methods():
    """ä¸»æˆåˆ†åˆ†æã§åˆ©ç”¨å¯èƒ½ãªæ‰‹æ³•ä¸€è¦§ã‚’å–å¾—"""
    return {
        "methods": [
            {
                "name": "standard",
                "display_name": "æ¨™æº–ä¸»æˆåˆ†åˆ†æ",
                "description": "ç›¸é–¢è¡Œåˆ—ã¾ãŸã¯å…±åˆ†æ•£è¡Œåˆ—ã«åŸºã¥ãä¸»æˆåˆ†åˆ†æ",
                "parameters": {
                    "n_components": {
                        "type": "integer",
                        "default": 2,
                        "min": 2,
                        "max": 10,
                        "description": "æŠ½å‡ºã™ã‚‹ä¸»æˆåˆ†æ•°",
                    },
                    "standardize": {
                        "type": "boolean",
                        "default": True,
                        "description": "ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ã‚’è¡Œã†ã‹",
                    },
                },
            }
        ],
        "guidelines": {
            "kmo_thresholds": {
                "excellent": {"value": 0.9, "label": "å„ªç§€"},
                "good": {"value": 0.8, "label": "è‰¯å¥½"},
                "adequate": {"value": 0.7, "label": "é©åˆ‡"},
                "poor": {"value": 0.6, "label": "ä¸è‰¯"},
                "unacceptable": {"value": 0.5, "label": "ä¸é©åˆ‡"},
            },
            "minimum_sample_size": "å¤‰æ•°æ•°ã®3å€ä»¥ä¸Šæ¨å¥¨",
            "minimum_variables": 2,
            "eigenvalue_threshold": 1.0,
        },
    }


@router.get("/parameters/validate")
async def validate_pca_parameters(
    n_components: int = Query(2, description="ä¸»æˆåˆ†æ•°"),
    standardize: bool = Query(True, description="æ¨™æº–åŒ–"),
):
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    validation_result = {"valid": True, "warnings": [], "errors": []}

    if n_components < 1:
        validation_result["errors"].append("ä¸»æˆåˆ†æ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        validation_result["valid"] = False
    elif n_components > 20:
        validation_result["warnings"].append(
            "ä¸»æˆåˆ†æ•°ãŒå¤šã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: â‰¤10ï¼‰"
        )

    return validation_result


@router.get("/interpretation")
async def get_interpretation_guide():
    """ä¸»æˆåˆ†åˆ†æçµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰ã‚’å–å¾—"""
    return {
        "kmo_interpretation": {
            "description": "Kaiser-Meyer-Olkiné©åˆåº¦æ¸¬åº¦",
            "ranges": {
                "0.9ä»¥ä¸Š": "å„ªç§€ - ä¸»æˆåˆ†åˆ†æã«éå¸¸ã«é©ã—ã¦ã„ã‚‹",
                "0.8-0.9": "è‰¯å¥½ - ä¸»æˆåˆ†åˆ†æã«é©ã—ã¦ã„ã‚‹",
                "0.7-0.8": "é©åˆ‡ - ä¸»æˆåˆ†åˆ†æãŒå¯èƒ½",
                "0.6-0.7": "ä¸è‰¯ - ä¸»æˆåˆ†åˆ†æã«ã¯ä¸é©åˆ‡",
                "0.6æœªæº€": "ä¸é©åˆ‡ - ä¸»æˆåˆ†åˆ†æã¯æ¨å¥¨ã•ã‚Œãªã„",
            },
        },
        "explained_variance": {
            "description": "å¯„ä¸ç‡ - å„ä¸»æˆåˆ†ãŒèª¬æ˜ã™ã‚‹åˆ†æ•£ã®å‰²åˆ",
            "interpretation": {
                "KaiseråŸºæº–": "å›ºæœ‰å€¤1ä»¥ä¸Šã®ä¸»æˆåˆ†ã‚’æ¡ç”¨",
                "ç´¯ç©å¯„ä¸ç‡": "70-80%ä»¥ä¸Šã§ååˆ†ãªèª¬æ˜åŠ›",
            },
        },
        "component_loadings": {
            "description": "ä¸»æˆåˆ†è² è·é‡ - å¤‰æ•°ã¨ä¸»æˆåˆ†ã®ç›¸é–¢ã®å¼·ã•",
            "ranges": {
                "0.7ä»¥ä¸Š": "å¼·ã„é–¢é€£",
                "0.5-0.7": "ä¸­ç¨‹åº¦ã®é–¢é€£",
                "0.3-0.5": "å¼±ã„é–¢é€£",
                "0.3æœªæº€": "ã»ã¨ã‚“ã©é–¢é€£ãªã—",
            },
        },
        "eigenvalue": {
            "description": "å›ºæœ‰å€¤ - å„ä¸»æˆåˆ†ãŒèª¬æ˜ã™ã‚‹åˆ†æ•£ã®å¤§ãã•",
            "interpretation": {
                "KaiseråŸºæº–": "å›ºæœ‰å€¤1ä»¥ä¸Šã®ä¸»æˆåˆ†ã‚’æ¡ç”¨",
                "ã‚¹ã‚¯ãƒªãƒ¼åŸºæº–": "ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã®æ€¥æ¿€ãªæ¸›å°‘ç‚¹ã¾ã§æ¡ç”¨",
            },
        },
    }


@router.get("/sessions/{session_id}")
async def get_pca_session_detail(
    session_id: int,
    db: Session = Depends(get_db),
):
    """ä¸»æˆåˆ†åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—"""
    try:
        print(f"ğŸ“Š ä¸»æˆåˆ†åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—é–‹å§‹: {session_id}")

        # PCAAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        analyzer = PCAAnalyzer()

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—
        session_detail = await analyzer.get_session_detail(session_id, db)

        print(f"ğŸ” å–å¾—ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°: {session_detail.get('success', False)}")

        if not session_detail or not session_detail.get("success"):
            error_msg = (
                session_detail.get("error", f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                if session_detail
                else f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )
            raise HTTPException(status_code=404, detail=error_msg)

        return JSONResponse(content=session_detail)

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ä¸»æˆåˆ†åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500,
            detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/download/{session_id}/details")
async def download_pca_details(session_id: int, db: Session = Depends(get_db)):
    """ä¸»æˆåˆ†åˆ†æçµæœè©³ç´°ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import (
            AnalysisSession,
            EigenvalueData,
            AnalysisMetadata,
            CoordinatesData,
        )

        print(f"Starting PCA details download for session: {session_id}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "pca":
            raise HTTPException(
                status_code=400, detail="ä¸»æˆåˆ†åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        print(f"Session found: {session.session_name}")

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata_entries = (
            db.query(AnalysisMetadata)
            .filter(AnalysisMetadata.session_id == session_id)
            .all()
        )

        # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        coordinates_data = (
            db.query(CoordinatesData)
            .filter(CoordinatesData.session_id == session_id)
            .all()
        )

        # å›ºæœ‰å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        eigenvalue_data = (
            db.query(EigenvalueData)
            .filter(EigenvalueData.session_id == session_id)
            .all()
        )

        print(
            f"Found {len(metadata_entries)} metadata entries, {len(coordinates_data)} coordinates, {len(eigenvalue_data)} eigenvalues"
        )

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"])
        writer.writerow(["é …ç›®", "å€¤"])
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³å", session.session_name])
        writer.writerow(["ãƒ•ã‚¡ã‚¤ãƒ«å", session.original_filename])
        writer.writerow(["åˆ†ææ‰‹æ³•", "ä¸»æˆåˆ†åˆ†æ"])
        writer.writerow(
            ["åˆ†ææ—¥æ™‚", session.analysis_timestamp.strftime("%Y-%m-%d %H:%M:%S")]
        )
        writer.writerow(["ã‚µãƒ³ãƒ—ãƒ«æ•°", session.row_count])
        writer.writerow(["å¤‰æ•°æ•°", session.column_count])
        writer.writerow([])

        # å›ºæœ‰å€¤ã¨å¯„ä¸ç‡
        if eigenvalue_data:
            writer.writerow(["ä¸»æˆåˆ†ã®å›ºæœ‰å€¤ã¨å¯„ä¸ç‡"])
            writer.writerow(["ä¸»æˆåˆ†", "å›ºæœ‰å€¤", "å¯„ä¸ç‡(%)", "ç´¯ç©å¯„ä¸ç‡(%)"])

            for eigenval in sorted(eigenvalue_data, key=lambda x: x.dimension_number):
                eigenvalue = eigenval.eigenvalue if eigenval.eigenvalue else 0
                explained_variance = (
                    eigenval.explained_inertia if eigenval.explained_inertia else 0
                )
                cumulative_variance = (
                    eigenval.cumulative_inertia if eigenval.cumulative_inertia else 0
                )

                writer.writerow(
                    [
                        f"PC{eigenval.dimension_number}",
                        f"{eigenvalue:.8f}",
                        f"{explained_variance*100:.2f}",
                        f"{cumulative_variance*100:.2f}",
                    ]
                )
            writer.writerow([])

        # ä¸»æˆåˆ†è² è·é‡ï¼ˆå¤‰æ•°åº§æ¨™ï¼‰
        variable_coords = [
            coord for coord in coordinates_data if coord.point_type == "variable"
        ]
        if variable_coords:
            writer.writerow(["ä¸»æˆåˆ†è² è·é‡"])
            writer.writerow(["å¤‰æ•°å", "PC1", "PC2", "PC3", "PC4"])
            for coord in variable_coords:
                writer.writerow(
                    [
                        coord.point_name,
                        f"{coord.dimension_1:.6f}" if coord.dimension_1 else "0.000000",
                        f"{coord.dimension_2:.6f}" if coord.dimension_2 else "0.000000",
                        f"{coord.dimension_3:.6f}" if coord.dimension_3 else "0.000000",
                        f"{coord.dimension_4:.6f}" if coord.dimension_4 else "0.000000",
                    ]
                )
            writer.writerow([])

        # ä¸»æˆåˆ†å¾—ç‚¹ï¼ˆã‚µãƒ³ãƒ—ãƒ«åº§æ¨™ï¼‰
        sample_coords = [
            coord for coord in coordinates_data if coord.point_type == "observation"
        ]
        if sample_coords:
            writer.writerow(["ä¸»æˆåˆ†å¾—ç‚¹"])
            writer.writerow(["ã‚µãƒ³ãƒ—ãƒ«å", "PC1", "PC2", "PC3", "PC4"])
            for coord in sample_coords:
                writer.writerow(
                    [
                        coord.point_name,
                        f"{coord.dimension_1:.6f}" if coord.dimension_1 else "0.000000",
                        f"{coord.dimension_2:.6f}" if coord.dimension_2 else "0.000000",
                        f"{coord.dimension_3:.6f}" if coord.dimension_3 else "0.000000",
                        f"{coord.dimension_4:.6f}" if coord.dimension_4 else "0.000000",
                    ]
                )
            writer.writerow([])

        # CSVå†…å®¹ã‚’å–å¾—
        csv_content = output.getvalue()
        output.close()

        print(f"Generated CSV content length: {len(csv_content)} characters")

        # ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
        filename = f"pca_details_{session_id}.csv"

        # Responseã‚’ä½œæˆ
        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv",
            headers={"Content-Disposition": f'attachment; filename="{filename}"'},
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"è©³ç´°CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=500, detail=f"è©³ç´°CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/download/{session_id}/loadings")
async def download_pca_loadings(session_id: int, db: Session = Depends(get_db)):
    """ä¸»æˆåˆ†è² è·é‡ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, CoordinatesData

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "pca":
            raise HTTPException(
                status_code=400, detail="ä¸»æˆåˆ†åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        # å¤‰æ•°åº§æ¨™ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸»æˆåˆ†è² è·é‡ï¼‰ã‚’å–å¾—
        loadings = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "variable",
            )
            .all()
        )

        if not loadings:
            raise HTTPException(status_code=404, detail="ä¸»æˆåˆ†è² è·é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow(["variable_name", "PC1", "PC2", "PC3", "PC4"])

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for loading in loadings:
            writer.writerow(
                [
                    loading.point_name,
                    loading.dimension_1 if loading.dimension_1 is not None else 0.0,
                    loading.dimension_2 if loading.dimension_2 is not None else 0.0,
                    loading.dimension_3 if loading.dimension_3 is not None else 0.0,
                    loading.dimension_4 if loading.dimension_4 is not None else 0.0,
                ]
            )

        output.seek(0)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = StreamingResponse(
            io.StringIO(output.getvalue()),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=pca_loadings_{session_id}.csv"
            },
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        print(f"ä¸»æˆåˆ†è² è·é‡CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ä¸»æˆåˆ†è² è·é‡CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/download/{session_id}/scores")
async def download_pca_scores(session_id: int, db: Session = Depends(get_db)):
    """ä¸»æˆåˆ†å¾—ç‚¹ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, CoordinatesData

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "pca":
            raise HTTPException(
                status_code=400, detail="ä¸»æˆåˆ†åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        # ã‚µãƒ³ãƒ—ãƒ«åº§æ¨™ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸»æˆåˆ†å¾—ç‚¹ï¼‰ã‚’å–å¾—
        scores = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "observation",
            )
            .all()
        )

        if not scores:
            raise HTTPException(status_code=404, detail="ä¸»æˆåˆ†å¾—ç‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow(["sample_name", "PC1", "PC2", "PC3", "PC4"])

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for score in scores:
            writer.writerow(
                [
                    score.point_name,
                    score.dimension_1 if score.dimension_1 is not None else 0.0,
                    score.dimension_2 if score.dimension_2 is not None else 0.0,
                    score.dimension_3 if score.dimension_3 is not None else 0.0,
                    score.dimension_4 if score.dimension_4 is not None else 0.0,
                ]
            )

        output.seek(0)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = StreamingResponse(
            io.StringIO(output.getvalue()),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=pca_scores_{session_id}.csv"
            },
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        print(f"ä¸»æˆåˆ†å¾—ç‚¹CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ä¸»æˆåˆ†å¾—ç‚¹CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/debug/sessions")
async def debug_pca_sessions(
    user_id: str = Query("default"), db: Session = Depends(get_db)
):
    """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šPCAã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ç¢ºèª"""
    try:
        from models import AnalysisSession

        print(f"ğŸ”§ PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒãƒƒã‚°é–‹å§‹: user_id='{user_id}'")

        # å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—
        all_sessions = (
            db.query(AnalysisSession)
            .filter(AnalysisSession.user_id == user_id)
            .order_by(AnalysisSession.analysis_timestamp.desc())
            .limit(50)
            .all()
        )

        # åˆ†æã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
        type_counts = {}
        pca_sessions = []
        session_details = []

        for session in all_sessions:
            analysis_type = session.analysis_type or "null"
            type_counts[analysis_type] = type_counts.get(analysis_type, 0) + 1

            session_info = {
                "id": session.id,
                "name": session.session_name,
                "type": session.analysis_type,
                "filename": session.original_filename,
                "timestamp": (
                    session.analysis_timestamp.isoformat()
                    if session.analysis_timestamp
                    else None
                ),
                "row_count": session.row_count,
                "column_count": session.column_count,
            }
            session_details.append(session_info)

            # PCAé–¢é€£ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
            if analysis_type in ["pca", "PCA", "principal_component_analysis"]:
                pca_sessions.append(session_info)

        print(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°çµæœ:")
        print(f"  - ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(all_sessions)}")
        print(f"  - PCAã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(pca_sessions)}")
        print(f"  - åˆ†æã‚¿ã‚¤ãƒ—åˆ†å¸ƒ: {type_counts}")

        return {
            "success": True,
            "debug_info": {
                "user_id": user_id,
                "total_sessions": len(all_sessions),
                "pca_sessions_count": len(pca_sessions),
                "type_distribution": type_counts,
                "all_sessions": session_details,
                "pca_sessions_only": pca_sessions,
                "timestamp": datetime.now().isoformat(),
            },
            "recommendations": [
                f"PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€æ–°ã—ã„åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„",
                f"analysis_typeãŒ'pca'ä»¥å¤–ã«ãªã£ã¦ã„ã‚‹å ´åˆã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜å‡¦ç†ã«å•é¡ŒãŒã‚ã‚Šã¾ã™",
                f"ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(all_sessions)}, PCA: {len(pca_sessions)}",
            ],
        }

    except Exception as e:
        print(f"âŒ PCAãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"PCAãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")


@router.post("/debug/fix-analysis-type")
async def fix_pca_analysis_type(
    user_id: str = Query("default"), db: Session = Depends(get_db)
):
    """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®analysis_typeã‚’ä¿®æ­£"""
    try:
        from models import AnalysisSession

        print(f"ğŸ”§ PCA analysis_typeä¿®æ­£é–‹å§‹: user_id='{user_id}'")

        # PCAé–¢é€£ã¨æ€ã‚ã‚Œã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
        sessions_to_fix = (
            db.query(AnalysisSession)
            .filter(AnalysisSession.user_id == user_id)
            .filter(
                # analysis_typeãŒnullã¾ãŸã¯ç©ºã€ã‚‚ã—ãã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³åã«PCAãŒå«ã¾ã‚Œã‚‹
                (AnalysisSession.analysis_type.is_(None))
                | (AnalysisSession.analysis_type == "")
                | (AnalysisSession.session_name.ilike("%pca%"))
                | (AnalysisSession.session_name.ilike("%ä¸»æˆåˆ†%"))
                | (AnalysisSession.original_filename.ilike("%pca%"))
            )
            .all()
        )

        fixed_count = 0
        for session in sessions_to_fix:
            old_type = session.analysis_type
            session.analysis_type = "pca"  # å¼·åˆ¶çš„ã«PCAã«è¨­å®š
            fixed_count += 1
            print(f"  ä¿®æ­£: Session {session.id}: '{old_type}' â†’ 'pca'")

        if fixed_count > 0:
            db.commit()
            print(f"âœ… {fixed_count}ä»¶ã®analysis_typeã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
        else:
            print(f"ä¿®æ­£å¯¾è±¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        return {
            "success": True,
            "fixed_count": fixed_count,
            "message": f"{fixed_count}ä»¶ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®analysis_typeã‚’'pca'ã«ä¿®æ­£ã—ã¾ã—ãŸ",
            "details": [
                {
                    "id": session.id,
                    "name": session.session_name,
                    "old_type": None,  # ä¿®æ­£å‰ã®å€¤ã¯è¨˜éŒ²ã—ã¦ã„ãªã„
                    "new_type": "pca",
                }
                for session in sessions_to_fix
            ],
        }

    except Exception as e:
        print(f"âŒ PCA analysis_typeä¿®æ­£ã‚¨ãƒ©ãƒ¼: {str(e)}")
        db.rollback()
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500, detail=f"analysis_typeä¿®æ­£ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


# routers/pca.py ã®æœ€å¾Œã«ä»¥ä¸‹ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ ï¼ˆPCAå±¥æ­´å°‚ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå«ã‚€ï¼‰


@router.get("/sessions")
async def get_pca_sessions_list(
    user_id: str = Query("default", description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
    limit: int = Query(50, description="å–å¾—ä»¶æ•°"),
    offset: int = Query(0, description="ã‚ªãƒ•ã‚»ãƒƒãƒˆ"),
    db: Session = Depends(get_db),
):
    """PCAåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¸€è¦§ã‚’å–å¾—ï¼ˆanalysis_type='pca'ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰"""
    try:
        from models import AnalysisSession

        print(
            f"ğŸ“Š PCAå°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—: user_id='{user_id}', limit={limit}, offset={offset}"
        )

        # PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿ã‚’å–å¾—ï¼ˆanalysis_type='pca'ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        query = (
            db.query(AnalysisSession)
            .filter(
                AnalysisSession.user_id == user_id,
                AnalysisSession.analysis_type == "pca",
            )
            .order_by(AnalysisSession.analysis_timestamp.desc())
        )

        # ç·æ•°ã‚’å–å¾—
        total_count = query.count()
        print(f"ğŸ”¢ PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ç·æ•°: {total_count}")

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³é©ç”¨
        sessions = query.offset(offset).limit(limit).all()
        print(f"ğŸ“„ å–å¾—ã—ãŸPCAã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(sessions)}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
        session_list = []
        for session in sessions:
            # ã‚¿ã‚°ã‚’å®‰å…¨ã«å–å¾—ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«ä¾å­˜ã—ãªã„æ–¹æ³•ï¼‰
            tag_names = []
            try:
                # è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚¿ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è©¦è¡Œ
                tag_queries = [
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: SessionTag.tag_name
                    lambda: db.execute(
                        "SELECT tag_name FROM session_tags WHERE session_id = :session_id",
                        {"session_id": session.id},
                    ).fetchall(),
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: SessionTag.name
                    lambda: db.execute(
                        "SELECT name FROM session_tags WHERE session_id = :session_id",
                        {"session_id": session.id},
                    ).fetchall(),
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: tags ãƒ†ãƒ¼ãƒ–ãƒ«
                    lambda: db.execute(
                        "SELECT tag FROM tags WHERE session_id = :session_id",
                        {"session_id": session.id},
                    ).fetchall(),
                ]

                for query_func in tag_queries:
                    try:
                        tag_rows = query_func()
                        tag_names = [row[0] for row in tag_rows if row[0]]
                        if tag_names:  # ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã£ãŸã‚‰çµ‚äº†
                            break
                    except Exception as tag_error:
                        continue  # æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œ

            except Exception as e:
                print(f"âš ï¸ ã‚¿ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼ (session {session.id}): {e}")
                tag_names = []  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºãƒªã‚¹ãƒˆ

            session_data = {
                "id": session.id,
                "session_id": session.id,  # äº’æ›æ€§ã®ãŸã‚
                "session_name": session.session_name,
                "description": session.description or "",
                "analysis_type": session.analysis_type,
                "filename": session.original_filename or session.filename,
                "original_filename": session.original_filename or session.filename,
                "row_count": session.row_count,
                "column_count": session.column_count,
                "analysis_timestamp": (
                    session.analysis_timestamp.isoformat()
                    if session.analysis_timestamp
                    else None
                ),
                "user_id": session.user_id,
                "tags": tag_names,
                # PCAç‰¹æœ‰ã®æƒ…å ±
                "dimensions_count": getattr(session, "dimensions_count", 2),
                "dimension_1_contribution": (
                    float(session.dimension_1_contribution)
                    if getattr(session, "dimension_1_contribution", None) is not None
                    else 0.0
                ),
                "dimension_2_contribution": (
                    float(session.dimension_2_contribution)
                    if getattr(session, "dimension_2_contribution", None) is not None
                    else 0.0
                ),
                "standardized": getattr(session, "standardized", True),
                "kmo": (
                    float(session.chi2_value)
                    if getattr(session, "chi2_value", None) is not None
                    else 0.0
                ),
                "chi2_value": (
                    float(session.chi2_value)
                    if getattr(session, "chi2_value", None) is not None
                    else 0.0
                ),
            }
            session_list.append(session_data)

        print(f"âœ… PCAå°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—å®Œäº†: {len(session_list)}ä»¶")

        return JSONResponse(
            content={
                "success": True,
                "data": session_list,
                "total": total_count,
                "limit": limit,
                "offset": offset,
                "has_more": offset + len(session_list) < total_count,
            }
        )

    except Exception as e:
        print(f"âŒ PCAå°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500, detail=f"PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.get("/sessions-simple")
async def get_pca_sessions_simple(
    user_id: str = Query("default", description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
    limit: int = Query(50, description="å–å¾—ä»¶æ•°"),
    offset: int = Query(0, description="ã‚ªãƒ•ã‚»ãƒƒãƒˆ"),
    db: Session = Depends(get_db),
):
    """PCAåˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¸€è¦§ã‚’å–å¾—ï¼ˆã‚¿ã‚°ãªã—ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    try:
        from models import AnalysisSession

        print(f"ğŸ“Š PCAå°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰: user_id='{user_id}'")

        # PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿ã‚’å–å¾—ï¼ˆanalysis_type='pca'ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        query = (
            db.query(AnalysisSession)
            .filter(
                AnalysisSession.user_id == user_id,
                AnalysisSession.analysis_type == "pca",
            )
            .order_by(AnalysisSession.analysis_timestamp.desc())
        )

        # ç·æ•°ã‚’å–å¾—
        total_count = query.count()
        print(f"ğŸ”¢ PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ç·æ•°: {total_count}")

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³é©ç”¨
        sessions = query.offset(offset).limit(limit).all()
        print(f"ğŸ“„ å–å¾—ã—ãŸPCAã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(sessions)}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢ï¼ˆã‚¿ã‚°ãªã—ï¼‰
        session_list = []
        for session in sessions:
            session_data = {
                "id": session.id,
                "session_id": session.id,  # äº’æ›æ€§ã®ãŸã‚
                "session_name": session.session_name,
                "description": session.description or "",
                "analysis_type": session.analysis_type,
                "filename": session.original_filename or session.filename,
                "original_filename": session.original_filename or session.filename,
                "row_count": session.row_count,
                "column_count": session.column_count,
                "analysis_timestamp": (
                    session.analysis_timestamp.isoformat()
                    if session.analysis_timestamp
                    else None
                ),
                "user_id": session.user_id,
                "tags": [],  # ã‚¿ã‚°ã¯ç©ºé…åˆ—ã§å›ºå®š
                # PCAç‰¹æœ‰ã®æƒ…å ±
                "dimensions_count": getattr(session, "dimensions_count", 2),
                "dimension_1_contribution": (
                    float(session.dimension_1_contribution)
                    if getattr(session, "dimension_1_contribution", None) is not None
                    else 0.0
                ),
                "dimension_2_contribution": (
                    float(session.dimension_2_contribution)
                    if getattr(session, "dimension_2_contribution", None) is not None
                    else 0.0
                ),
                "standardized": getattr(session, "standardized", True),
                "kmo": (
                    float(session.chi2_value)
                    if getattr(session, "chi2_value", None) is not None
                    else 0.0
                ),
                "chi2_value": (
                    float(session.chi2_value)
                    if getattr(session, "chi2_value", None) is not None
                    else 0.0
                ),
            }
            session_list.append(session_data)

        print(f"âœ… PCAå°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—å®Œäº†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰: {len(session_list)}ä»¶")

        return JSONResponse(
            content={
                "success": True,
                "data": session_list,
                "total": total_count,
                "limit": limit,
                "offset": offset,
                "has_more": offset + len(session_list) < total_count,
            }
        )

    except Exception as e:
        print(f"âŒ PCAå°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500,
            detail=f"PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰: {str(e)}",
        )


@router.get("/debug/sessions")
async def debug_pca_sessions(
    user_id: str = Query("default"), db: Session = Depends(get_db)
):
    """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šPCAã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ç¢ºèª"""
    try:
        from models import AnalysisSession

        print(f"ğŸ”§ PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒãƒƒã‚°é–‹å§‹: user_id='{user_id}'")

        # å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—
        all_sessions = (
            db.query(AnalysisSession)
            .filter(AnalysisSession.user_id == user_id)
            .order_by(AnalysisSession.analysis_timestamp.desc())
            .limit(50)
            .all()
        )

        # åˆ†æã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
        type_counts = {}
        pca_sessions = []
        session_details = []

        for session in all_sessions:
            analysis_type = session.analysis_type or "null"
            type_counts[analysis_type] = type_counts.get(analysis_type, 0) + 1

            session_info = {
                "id": session.id,
                "name": session.session_name,
                "type": session.analysis_type,
                "filename": session.original_filename,
                "timestamp": (
                    session.analysis_timestamp.isoformat()
                    if session.analysis_timestamp
                    else None
                ),
                "row_count": session.row_count,
                "column_count": session.column_count,
            }
            session_details.append(session_info)

            # PCAé–¢é€£ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
            if analysis_type in ["pca", "PCA", "principal_component_analysis"]:
                pca_sessions.append(session_info)

        print(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°çµæœ:")
        print(f"  - ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(all_sessions)}")
        print(f"  - PCAã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(pca_sessions)}")
        print(f"  - åˆ†æã‚¿ã‚¤ãƒ—åˆ†å¸ƒ: {type_counts}")

        return {
            "success": True,
            "debug_info": {
                "user_id": user_id,
                "total_sessions": len(all_sessions),
                "pca_sessions_count": len(pca_sessions),
                "type_distribution": type_counts,
                "all_sessions": session_details,
                "pca_sessions_only": pca_sessions,
                "timestamp": datetime.now().isoformat(),
            },
            "recommendations": [
                f"PCAã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€æ–°ã—ã„åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„",
                f"analysis_typeãŒ'pca'ä»¥å¤–ã«ãªã£ã¦ã„ã‚‹å ´åˆã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜å‡¦ç†ã«å•é¡ŒãŒã‚ã‚Šã¾ã™",
                f"ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(all_sessions)}, PCA: {len(pca_sessions)}",
            ],
        }

    except Exception as e:
        print(f"âŒ PCAãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"PCAãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")


@router.post("/debug/fix-analysis-type")
async def fix_pca_analysis_type(
    user_id: str = Query("default"), db: Session = Depends(get_db)
):
    """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®analysis_typeã‚’ä¿®æ­£"""
    try:
        from models import AnalysisSession

        print(f"ğŸ”§ PCA analysis_typeä¿®æ­£é–‹å§‹: user_id='{user_id}'")

        # PCAé–¢é€£ã¨æ€ã‚ã‚Œã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
        sessions_to_fix = (
            db.query(AnalysisSession)
            .filter(AnalysisSession.user_id == user_id)
            .filter(
                # analysis_typeãŒnullã¾ãŸã¯ç©ºã€ã‚‚ã—ãã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³åã«PCAãŒå«ã¾ã‚Œã‚‹
                (AnalysisSession.analysis_type.is_(None))
                | (AnalysisSession.analysis_type == "")
                | (AnalysisSession.session_name.ilike("%pca%"))
                | (AnalysisSession.session_name.ilike("%ä¸»æˆåˆ†%"))
                | (AnalysisSession.original_filename.ilike("%pca%"))
            )
            .all()
        )

        fixed_count = 0
        for session in sessions_to_fix:
            old_type = session.analysis_type
            session.analysis_type = "pca"  # å¼·åˆ¶çš„ã«PCAã«è¨­å®š
            fixed_count += 1
            print(f"  ä¿®æ­£: Session {session.id}: '{old_type}' â†’ 'pca'")

        if fixed_count > 0:
            db.commit()
            print(f"âœ… {fixed_count}ä»¶ã®analysis_typeã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
        else:
            print(f"ä¿®æ­£å¯¾è±¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        return {
            "success": True,
            "fixed_count": fixed_count,
            "message": f"{fixed_count}ä»¶ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®analysis_typeã‚’'pca'ã«ä¿®æ­£ã—ã¾ã—ãŸ",
            "details": [
                {
                    "id": session.id,
                    "name": session.session_name,
                    "old_type": None,  # ä¿®æ­£å‰ã®å€¤ã¯è¨˜éŒ²ã—ã¦ã„ãªã„
                    "new_type": "pca",
                }
                for session in sessions_to_fix
            ],
        }

    except Exception as e:
        print(f"âŒ PCA analysis_typeä¿®æ­£ã‚¨ãƒ©ãƒ¼: {str(e)}")
        db.rollback()
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500, detail=f"analysis_typeä¿®æ­£ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.post("/debug/fix-analysis-type")
async def fix_pca_analysis_type(
    user_id: str = Query("default"), db: Session = Depends(get_db)
):
    """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®analysis_typeã‚’ä¿®æ­£"""
    try:
        from models import AnalysisSession

        print(f"ğŸ”§ PCA analysis_typeä¿®æ­£é–‹å§‹: user_id='{user_id}'")

        # PCAé–¢é€£ã¨æ€ã‚ã‚Œã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
        sessions_to_fix = (
            db.query(AnalysisSession)
            .filter(AnalysisSession.user_id == user_id)
            .filter(
                # analysis_typeãŒnullã¾ãŸã¯ç©ºã€ã‚‚ã—ãã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³åã«PCAãŒå«ã¾ã‚Œã‚‹
                (AnalysisSession.analysis_type.is_(None))
                | (AnalysisSession.analysis_type == "")
                | (AnalysisSession.session_name.ilike("%pca%"))
                | (AnalysisSession.session_name.ilike("%ä¸»æˆåˆ†%"))
                | (AnalysisSession.original_filename.ilike("%pca%"))
            )
            .all()
        )

        fixed_count = 0
        for session in sessions_to_fix:
            old_type = session.analysis_type
            session.analysis_type = "pca"  # å¼·åˆ¶çš„ã«PCAã«è¨­å®š
            fixed_count += 1
            print(f"  ä¿®æ­£: Session {session.id}: '{old_type}' â†’ 'pca'")

        if fixed_count > 0:
            db.commit()
            print(f"âœ… {fixed_count}ä»¶ã®analysis_typeã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
        else:
            print(f"ä¿®æ­£å¯¾è±¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        return {
            "success": True,
            "fixed_count": fixed_count,
            "message": f"{fixed_count}ä»¶ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®analysis_typeã‚’'pca'ã«ä¿®æ­£ã—ã¾ã—ãŸ",
            "details": [
                {
                    "id": session.id,
                    "name": session.session_name,
                    "old_type": None,  # ä¿®æ­£å‰ã®å€¤ã¯è¨˜éŒ²ã—ã¦ã„ãªã„
                    "new_type": "pca",
                }
                for session in sessions_to_fix
            ],
        }

    except Exception as e:
        print(f"âŒ PCA analysis_typeä¿®æ­£ã‚¨ãƒ©ãƒ¼: {str(e)}")
        db.rollback()
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500, detail=f"analysis_typeä¿®æ­£ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )
