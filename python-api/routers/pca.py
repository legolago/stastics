from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Query
from fastapi.responses import JSONResponse, StreamingResponse, Response
from sqlalchemy.orm import Session
import pandas as pd
import numpy as np
import io
import csv
from typing import Optional, List

from models import get_db
from analysis.pca import PCAAnalyzer

router = APIRouter(prefix="/pca", tags=["pca"])


@router.post("/analyze")
async def analyze_pca(
    file: UploadFile = File(...),
    session_name: str = Query(..., description="åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³å"),
    description: Optional[str] = Query(None, description="åˆ†æã®èª¬æ˜"),
    tags: Optional[str] = Query(None, description="ã‚¿ã‚°ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰"),
    user_id: str = Query("default", description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
    n_components: int = Query(2, description="ä¸»æˆåˆ†æ•°"),
    standardize: bool = Query(True, description="æ¨™æº–åŒ–ã®å®Ÿè¡Œ"),
    db: Session = Depends(get_db),
):
    """ä¸»æˆåˆ†åˆ†æã‚’å®Ÿè¡Œ"""
    try:
        print(f"=== PCA APIå‘¼ã³å‡ºã—é–‹å§‹ ===")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³: {session_name}")
        print(f"ä¸»æˆåˆ†æ•°: {n_components}")
        print(f"æ¨™æº–åŒ–: {standardize}")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not file.filename.endswith(".csv"):
            raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™")

        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        contents = await file.read()
        try:
            csv_text = contents.decode("utf-8")
        except UnicodeDecodeError:
            csv_text = contents.decode("shift_jis")

        print(f"CSVãƒ†ã‚­ã‚¹ãƒˆ:\n{csv_text}")

        df = pd.read_csv(io.StringIO(csv_text), index_col=0)
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ :\n{df}")

        if df.empty:
            raise HTTPException(status_code=400, detail="ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡º
        numeric_df = df.select_dtypes(include=[np.number])
        if numeric_df.empty:
            raise HTTPException(
                status_code=400,
                detail="æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä¸»æˆåˆ†åˆ†æã«ã¯æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚",
            )

        # æ¬ æå€¤ã®å‡¦ç†
        if numeric_df.isnull().any().any():
            numeric_df = numeric_df.dropna()
            if numeric_df.empty:
                raise HTTPException(
                    status_code=400,
                    detail="æ¬ æå€¤ã‚’é™¤å»ã—ãŸçµæœã€ãƒ‡ãƒ¼ã‚¿ãŒç©ºã«ãªã‚Šã¾ã—ãŸã€‚",
                )

        # ã‚¿ã‚°å‡¦ç†
        tag_list = [tag.strip() for tag in tags.split(",")] if tags else []

        # åˆ†æå®Ÿè¡Œï¼ˆBaseAnalyzerã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ï¼‰
        analyzer = PCAAnalyzer()
        response_data = analyzer.run_full_analysis(
            df=numeric_df,
            db=db,
            session_name=session_name,
            description=description,
            tags=tag_list,
            user_id=user_id,
            file=file,
            csv_text=csv_text,
            n_components=n_components,
            standardize=standardize,
        )

        print("=== PCA APIå‡¦ç†å®Œäº† ===")
        return JSONResponse(content=response_data)

    except HTTPException:
        raise
    except Exception as e:
        print(f"=== PCA APIå‡¦ç†ã‚¨ãƒ©ãƒ¼ ===")
        print(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500, detail=f"PCAåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/methods")
async def get_pca_methods():
    """ä¸»æˆåˆ†åˆ†æã§åˆ©ç”¨å¯èƒ½ãªæ‰‹æ³•ä¸€è¦§ã‚’å–å¾—"""
    return {
        "methods": [
            {
                "name": "standard",
                "display_name": "æ¨™æº–ä¸»æˆåˆ†åˆ†æ",
                "description": "ç›¸é–¢è¡Œåˆ—ã¾ãŸã¯å…±åˆ†æ•£è¡Œåˆ—ã«åŸºã¥ãä¸»æˆåˆ†åˆ†æ",
                "parameters": {
                    "n_components": {
                        "type": "integer",
                        "default": 2,
                        "min": 2,
                        "max": 10,
                        "description": "æŠ½å‡ºã™ã‚‹ä¸»æˆåˆ†æ•°",
                    },
                    "standardize": {
                        "type": "boolean",
                        "default": True,
                        "description": "ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ã‚’è¡Œã†ã‹",
                    },
                },
            }
        ],
        "guidelines": {
            "kmo_thresholds": {
                "excellent": {"value": 0.9, "label": "å„ªç§€"},
                "good": {"value": 0.8, "label": "è‰¯å¥½"},
                "adequate": {"value": 0.7, "label": "é©åˆ‡"},
                "poor": {"value": 0.6, "label": "ä¸è‰¯"},
                "unacceptable": {"value": 0.5, "label": "ä¸é©åˆ‡"},
            },
            "minimum_sample_size": "å¤‰æ•°æ•°ã®3å€ä»¥ä¸Šæ¨å¥¨",
            "minimum_variables": 2,
            "eigenvalue_threshold": 1.0,
        },
    }


@router.get("/parameters/validate")
async def validate_pca_parameters(
    n_components: int = Query(2, description="ä¸»æˆåˆ†æ•°"),
    standardize: bool = Query(True, description="æ¨™æº–åŒ–"),
):
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    validation_result = {"valid": True, "warnings": [], "errors": []}

    if n_components < 1:
        validation_result["errors"].append("ä¸»æˆåˆ†æ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        validation_result["valid"] = False
    elif n_components > 20:
        validation_result["warnings"].append(
            "ä¸»æˆåˆ†æ•°ãŒå¤šã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: â‰¤10ï¼‰"
        )

    return validation_result


@router.get("/interpretation")
async def get_interpretation_guide():
    """ä¸»æˆåˆ†åˆ†æçµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰ã‚’å–å¾—"""
    return {
        "kmo_interpretation": {
            "description": "Kaiser-Meyer-Olkiné©åˆåº¦æ¸¬åº¦",
            "ranges": {
                "0.9ä»¥ä¸Š": "å„ªç§€ - ä¸»æˆåˆ†åˆ†æã«éå¸¸ã«é©ã—ã¦ã„ã‚‹",
                "0.8-0.9": "è‰¯å¥½ - ä¸»æˆåˆ†åˆ†æã«é©ã—ã¦ã„ã‚‹",
                "0.7-0.8": "é©åˆ‡ - ä¸»æˆåˆ†åˆ†æãŒå¯èƒ½",
                "0.6-0.7": "ä¸è‰¯ - ä¸»æˆåˆ†åˆ†æã«ã¯ä¸é©åˆ‡",
                "0.6æœªæº€": "ä¸é©åˆ‡ - ä¸»æˆåˆ†åˆ†æã¯æ¨å¥¨ã•ã‚Œãªã„",
            },
        },
        "explained_variance": {
            "description": "å¯„ä¸ç‡ - å„ä¸»æˆåˆ†ãŒèª¬æ˜ã™ã‚‹åˆ†æ•£ã®å‰²åˆ",
            "interpretation": {
                "KaiseråŸºæº–": "å›ºæœ‰å€¤1ä»¥ä¸Šã®ä¸»æˆåˆ†ã‚’æ¡ç”¨",
                "ç´¯ç©å¯„ä¸ç‡": "70-80%ä»¥ä¸Šã§ååˆ†ãªèª¬æ˜åŠ›",
            },
        },
        "component_loadings": {
            "description": "ä¸»æˆåˆ†è² è·é‡ - å¤‰æ•°ã¨ä¸»æˆåˆ†ã®ç›¸é–¢ã®å¼·ã•",
            "ranges": {
                "0.7ä»¥ä¸Š": "å¼·ã„é–¢é€£",
                "0.5-0.7": "ä¸­ç¨‹åº¦ã®é–¢é€£",
                "0.3-0.5": "å¼±ã„é–¢é€£",
                "0.3æœªæº€": "ã»ã¨ã‚“ã©é–¢é€£ãªã—",
            },
        },
        "eigenvalue": {
            "description": "å›ºæœ‰å€¤ - å„ä¸»æˆåˆ†ãŒèª¬æ˜ã™ã‚‹åˆ†æ•£ã®å¤§ãã•",
            "interpretation": {
                "KaiseråŸºæº–": "å›ºæœ‰å€¤1ä»¥ä¸Šã®ä¸»æˆåˆ†ã‚’æ¡ç”¨",
                "ã‚¹ã‚¯ãƒªãƒ¼åŸºæº–": "ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã®æ€¥æ¿€ãªæ¸›å°‘ç‚¹ã¾ã§æ¡ç”¨",
            },
        },
    }


@router.get("/sessions/{session_id}")
async def get_pca_session_detail(
    session_id: int,
    db: Session = Depends(get_db),
):
    """ä¸»æˆåˆ†åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—"""
    try:
        print(f"ğŸ“Š ä¸»æˆåˆ†åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—é–‹å§‹: {session_id}")

        # PCAAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        analyzer = PCAAnalyzer()

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—
        session_detail = await analyzer.get_session_detail(session_id, db)

        print(f"ğŸ” å–å¾—ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°: {session_detail.get('success', False)}")

        if not session_detail or not session_detail.get("success"):
            error_msg = (
                session_detail.get("error", f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                if session_detail
                else f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )
            raise HTTPException(status_code=404, detail=error_msg)

        return JSONResponse(content=session_detail)

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ä¸»æˆåˆ†åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        print(f"è©³ç´°:\n{traceback.format_exc()}")

        raise HTTPException(
            status_code=500,
            detail=f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/download/{session_id}/details")
async def download_pca_details(session_id: int, db: Session = Depends(get_db)):
    """ä¸»æˆåˆ†åˆ†æçµæœè©³ç´°ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import (
            AnalysisSession,
            EigenvalueData,
            AnalysisMetadata,
            CoordinatesData,
        )

        print(f"Starting PCA details download for session: {session_id}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "pca":
            raise HTTPException(
                status_code=400, detail="ä¸»æˆåˆ†åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        print(f"Session found: {session.session_name}")

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata_entries = (
            db.query(AnalysisMetadata)
            .filter(AnalysisMetadata.session_id == session_id)
            .all()
        )

        # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        coordinates_data = (
            db.query(CoordinatesData)
            .filter(CoordinatesData.session_id == session_id)
            .all()
        )

        # å›ºæœ‰å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        eigenvalue_data = (
            db.query(EigenvalueData)
            .filter(EigenvalueData.session_id == session_id)
            .all()
        )

        print(
            f"Found {len(metadata_entries)} metadata entries, {len(coordinates_data)} coordinates, {len(eigenvalue_data)} eigenvalues"
        )

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"])
        writer.writerow(["é …ç›®", "å€¤"])
        writer.writerow(["ã‚»ãƒƒã‚·ãƒ§ãƒ³å", session.session_name])
        writer.writerow(["ãƒ•ã‚¡ã‚¤ãƒ«å", session.original_filename])
        writer.writerow(["åˆ†ææ‰‹æ³•", "ä¸»æˆåˆ†åˆ†æ"])
        writer.writerow(
            ["åˆ†ææ—¥æ™‚", session.analysis_timestamp.strftime("%Y-%m-%d %H:%M:%S")]
        )
        writer.writerow(["ã‚µãƒ³ãƒ—ãƒ«æ•°", session.row_count])
        writer.writerow(["å¤‰æ•°æ•°", session.column_count])
        writer.writerow([])

        # å›ºæœ‰å€¤ã¨å¯„ä¸ç‡
        if eigenvalue_data:
            writer.writerow(["ä¸»æˆåˆ†ã®å›ºæœ‰å€¤ã¨å¯„ä¸ç‡"])
            writer.writerow(["ä¸»æˆåˆ†", "å›ºæœ‰å€¤", "å¯„ä¸ç‡(%)", "ç´¯ç©å¯„ä¸ç‡(%)"])

            for eigenval in sorted(eigenvalue_data, key=lambda x: x.dimension_number):
                eigenvalue = eigenval.eigenvalue if eigenval.eigenvalue else 0
                explained_variance = (
                    eigenval.explained_inertia if eigenval.explained_inertia else 0
                )
                cumulative_variance = (
                    eigenval.cumulative_inertia if eigenval.cumulative_inertia else 0
                )

                writer.writerow(
                    [
                        f"PC{eigenval.dimension_number}",
                        f"{eigenvalue:.8f}",
                        f"{explained_variance*100:.2f}",
                        f"{cumulative_variance*100:.2f}",
                    ]
                )
            writer.writerow([])

        # ä¸»æˆåˆ†è² è·é‡ï¼ˆå¤‰æ•°åº§æ¨™ï¼‰
        variable_coords = [
            coord for coord in coordinates_data if coord.point_type == "variable"
        ]
        if variable_coords:
            writer.writerow(["ä¸»æˆåˆ†è² è·é‡"])
            writer.writerow(["å¤‰æ•°å", "PC1", "PC2", "PC3", "PC4"])
            for coord in variable_coords:
                writer.writerow(
                    [
                        coord.point_name,
                        f"{coord.dimension_1:.6f}" if coord.dimension_1 else "0.000000",
                        f"{coord.dimension_2:.6f}" if coord.dimension_2 else "0.000000",
                        f"{coord.dimension_3:.6f}" if coord.dimension_3 else "0.000000",
                        f"{coord.dimension_4:.6f}" if coord.dimension_4 else "0.000000",
                    ]
                )
            writer.writerow([])

        # ä¸»æˆåˆ†å¾—ç‚¹ï¼ˆã‚µãƒ³ãƒ—ãƒ«åº§æ¨™ï¼‰
        sample_coords = [
            coord for coord in coordinates_data if coord.point_type == "observation"
        ]
        if sample_coords:
            writer.writerow(["ä¸»æˆåˆ†å¾—ç‚¹"])
            writer.writerow(["ã‚µãƒ³ãƒ—ãƒ«å", "PC1", "PC2", "PC3", "PC4"])
            for coord in sample_coords:
                writer.writerow(
                    [
                        coord.point_name,
                        f"{coord.dimension_1:.6f}" if coord.dimension_1 else "0.000000",
                        f"{coord.dimension_2:.6f}" if coord.dimension_2 else "0.000000",
                        f"{coord.dimension_3:.6f}" if coord.dimension_3 else "0.000000",
                        f"{coord.dimension_4:.6f}" if coord.dimension_4 else "0.000000",
                    ]
                )
            writer.writerow([])

        # CSVå†…å®¹ã‚’å–å¾—
        csv_content = output.getvalue()
        output.close()

        print(f"Generated CSV content length: {len(csv_content)} characters")

        # ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
        filename = f"pca_details_{session_id}.csv"

        # Responseã‚’ä½œæˆ
        return Response(
            content=csv_content.encode("utf-8-sig"),
            media_type="text/csv",
            headers={"Content-Disposition": f'attachment; filename="{filename}"'},
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"è©³ç´°CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=500, detail=f"è©³ç´°CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@router.get("/download/{session_id}/loadings")
async def download_pca_loadings(session_id: int, db: Session = Depends(get_db)):
    """ä¸»æˆåˆ†è² è·é‡ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, CoordinatesData

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "pca":
            raise HTTPException(
                status_code=400, detail="ä¸»æˆåˆ†åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        # å¤‰æ•°åº§æ¨™ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸»æˆåˆ†è² è·é‡ï¼‰ã‚’å–å¾—
        loadings = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "variable",
            )
            .all()
        )

        if not loadings:
            raise HTTPException(status_code=404, detail="ä¸»æˆåˆ†è² è·é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow(["variable_name", "PC1", "PC2", "PC3", "PC4"])

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for loading in loadings:
            writer.writerow(
                [
                    loading.point_name,
                    loading.dimension_1 if loading.dimension_1 is not None else 0.0,
                    loading.dimension_2 if loading.dimension_2 is not None else 0.0,
                    loading.dimension_3 if loading.dimension_3 is not None else 0.0,
                    loading.dimension_4 if loading.dimension_4 is not None else 0.0,
                ]
            )

        output.seek(0)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = StreamingResponse(
            io.StringIO(output.getvalue()),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=pca_loadings_{session_id}.csv"
            },
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        print(f"ä¸»æˆåˆ†è² è·é‡CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ä¸»æˆåˆ†è² è·é‡CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )


@router.get("/download/{session_id}/scores")
async def download_pca_scores(session_id: int, db: Session = Depends(get_db)):
    """ä¸»æˆåˆ†å¾—ç‚¹ã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        from models import AnalysisSession, CoordinatesData

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        session = (
            db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        )
        if not session:
            raise HTTPException(status_code=404, detail="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        if session.analysis_type != "pca":
            raise HTTPException(
                status_code=400, detail="ä¸»æˆåˆ†åˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            )

        # ã‚µãƒ³ãƒ—ãƒ«åº§æ¨™ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸»æˆåˆ†å¾—ç‚¹ï¼‰ã‚’å–å¾—
        scores = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "observation",
            )
            .all()
        )

        if not scores:
            raise HTTPException(status_code=404, detail="ä¸»æˆåˆ†å¾—ç‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow(["sample_name", "PC1", "PC2", "PC3", "PC4"])

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for score in scores:
            writer.writerow(
                [
                    score.point_name,
                    score.dimension_1 if score.dimension_1 is not None else 0.0,
                    score.dimension_2 if score.dimension_2 is not None else 0.0,
                    score.dimension_3 if score.dimension_3 is not None else 0.0,
                    score.dimension_4 if score.dimension_4 is not None else 0.0,
                ]
            )

        output.seek(0)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = StreamingResponse(
            io.StringIO(output.getvalue()),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=pca_scores_{session_id}.csv"
            },
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        print(f"ä¸»æˆåˆ†å¾—ç‚¹CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ä¸»æˆåˆ†å¾—ç‚¹CSVå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
        )
