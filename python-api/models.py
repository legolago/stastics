from sqlalchemy import (
    create_engine,
    Column,
    Integer,
    String,
    Text,
    DECIMAL,
    TIMESTAMP,
    ForeignKey,
    LargeBinary,
    ARRAY,
    UniqueConstraint,
    Float,
    Boolean,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, relationship
from sqlalchemy.dialects.postgresql import JSONB
from datetime import datetime
import os

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š
DATABASE_URL = f"postgresql://{os.getenv('DB_USER', 'user')}:{os.getenv('DB_PASSWORD', 'password')}@{os.getenv('DB_HOST', 'db')}:{os.getenv('DB_PORT', '5432')}/{os.getenv('DB_NAME', 'analysis')}"

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()


class AnalysisSession(Base):
    __tablename__ = "analysis_sessions"

    id = Column(Integer, primary_key=True, index=True)
    session_name = Column(String(255), nullable=False)
    original_filename = Column(String(255), nullable=False)
    file_size = Column(Integer)
    upload_timestamp = Column(TIMESTAMP, default=datetime.utcnow)
    analysis_timestamp = Column(TIMESTAMP, default=datetime.utcnow)
    description = Column(Text)
    tags = Column(ARRAY(String))
    user_id = Column(String(100))

    # ğŸ†• åˆ†ææ‰‹æ³•ã®ç¨®é¡ã‚’è¿½åŠ 
    analysis_type = Column(String(50))
    row_count = Column(Integer)
    column_count = Column(Integer)
    dimensions_count = Column(Integer)
    dimension_1_contribution = Column(Float)
    dimension_2_contribution = Column(Float)
    rotation = Column(String(50))  # 'varimax', 'promax', etc.
    standardized = Column(Boolean)
    total_inertia = Column(Float)
    chi2_value = Column(Float)
    degrees_of_freedom = Column(Integer)

    # åˆ†æçµæœã®çµ±è¨ˆæƒ…å ±
    total_inertia = Column(DECIMAL(10, 8))
    chi2_value = Column(DECIMAL(15, 4))
    degrees_of_freedom = Column(Integer)
    row_count = Column(Integer)
    column_count = Column(Integer)

    # æ¬¡å…ƒæ•°ã¨å¯„ä¸ç‡
    dimensions_count = Column(Integer, default=2)
    dimension_1_contribution = Column(DECIMAL(8, 6))
    dimension_2_contribution = Column(DECIMAL(8, 6))

    # åˆ†æè¨­å®š
    analysis_parameters = Column(JSONB)

    # RFMåˆ†æå›ºæœ‰ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å¾Œã«ï¼‰
    total_customers = Column(Integer, nullable=True)  # ç·é¡§å®¢æ•°
    analysis_period_days = Column(Integer, nullable=True)  # åˆ†ææœŸé–“ï¼ˆæ—¥æ•°ï¼‰

    created_at = Column(TIMESTAMP, default=datetime.utcnow)
    updated_at = Column(TIMESTAMP, default=datetime.utcnow)

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    original_data = relationship(
        "OriginalData", back_populates="session", cascade="all, delete-orphan"
    )
    coordinates = relationship(
        "CoordinatesData", back_populates="session", cascade="all, delete-orphan"
    )
    visualizations = relationship(
        "VisualizationData", back_populates="session", cascade="all, delete-orphan"
    )
    eigenvalues = relationship(
        "EigenvalueData", back_populates="session", cascade="all, delete-orphan"
    )
    # ğŸ†• æ–°ã—ã„ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    metadata_entries = relationship(
        "AnalysisMetadata", back_populates="session", cascade="all, delete-orphan"
    )


class OriginalData(Base):
    __tablename__ = "original_data"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("analysis_sessions.id"), nullable=False)
    csv_data = Column(Text, nullable=False)
    row_names = Column(ARRAY(String))
    column_names = Column(ARRAY(String))
    data_matrix = Column(JSONB)

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    session = relationship("AnalysisSession", back_populates="original_data")


class CoordinatesData(Base):
    __tablename__ = "coordinates_data"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("analysis_sessions.id"), nullable=False)
    # ğŸ†• æ‹¡å¼µã•ã‚ŒãŸpoint_type: 'row', 'column', 'observation', 'variable', 'factor', 'customer'
    point_type = Column(String(20), nullable=False)
    point_name = Column(String(255), nullable=False)
    dimension_1 = Column(DECIMAL(12, 8))
    dimension_2 = Column(DECIMAL(12, 8))
    contribution_dim1 = Column(DECIMAL(8, 6))
    contribution_dim2 = Column(DECIMAL(8, 6))
    quality_representation = Column(DECIMAL(8, 6))

    # è¿½åŠ ã®æ¬¡å…ƒ
    dimension_3 = Column(DECIMAL(12, 8))
    dimension_4 = Column(DECIMAL(12, 8))

    # ğŸ†• ä¸€æ„åˆ¶ç´„ã®åå‰ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
    __table_args__ = (
        UniqueConstraint(
            "session_id",
            "point_type",
            "point_name",
            name="uq_coordinates_session_type_name",
        ),
    )

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    session = relationship("AnalysisSession", back_populates="coordinates")


class VisualizationData(Base):
    __tablename__ = "visualization_data"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("analysis_sessions.id"), nullable=False)
    # ğŸ†• æ‹¡å¼µã•ã‚ŒãŸimage_type
    image_type = Column(String(50), default="correspondence_plot")
    image_data = Column(LargeBinary, nullable=True)
    image_base64 = Column(Text)
    image_size = Column(Integer)
    width = Column(Integer)
    height = Column(Integer)
    dpi = Column(Integer, default=300)
    created_at = Column(TIMESTAMP, default=datetime.utcnow)

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    session = relationship("AnalysisSession", back_populates="visualizations")


class EigenvalueData(Base):
    __tablename__ = "eigenvalue_data"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("analysis_sessions.id"), nullable=False)
    dimension_number = Column(Integer, nullable=False)
    eigenvalue = Column(DECIMAL(12, 8))
    explained_inertia = Column(DECIMAL(8, 6))
    cumulative_inertia = Column(DECIMAL(8, 6))

    # ğŸ†• ä¸€æ„åˆ¶ç´„ã®åå‰ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
    __table_args__ = (
        UniqueConstraint(
            "session_id", "dimension_number", name="uq_eigenvalue_session_dimension"
        ),
    )

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    session = relationship("AnalysisSession", back_populates="eigenvalues")


# ğŸ†• æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«: åˆ†ææ‰‹æ³•å›ºæœ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
class AnalysisMetadata(Base):
    __tablename__ = "analysis_metadata"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("analysis_sessions.id"), nullable=False)
    metadata_type = Column(
        String(50), nullable=False
    )  # 'pca_loadings', 'factor_loadings', etc.
    metadata_content = Column(JSONB, nullable=False)
    created_at = Column(TIMESTAMP, default=datetime.utcnow)

    # ğŸ†• ä¸€æ„åˆ¶ç´„
    __table_args__ = (
        UniqueConstraint(
            "session_id", "metadata_type", name="uq_metadata_session_type"
        ),
    )

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    session = relationship("AnalysisSession", back_populates="metadata_entries")


# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¾å­˜æ€§æ³¨å…¥ç”¨
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
def create_tables():
    Base.metadata.create_all(bind=engine)


# ğŸ†• åˆ†ææ‰‹æ³•åˆ¥ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def get_sessions_by_analysis_type(
    db, analysis_type: str, user_id: str = None, limit: int = 50, offset: int = 0
):
    """åˆ†ææ‰‹æ³•åˆ¥ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
    query = db.query(AnalysisSession).filter(
        AnalysisSession.analysis_type == analysis_type
    )

    if user_id:
        query = query.filter(AnalysisSession.user_id == user_id)

    return (
        query.order_by(AnalysisSession.analysis_timestamp.desc())
        .offset(offset)
        .limit(limit)
        .all()
    )


def get_analysis_summary_stats(db):
    """åˆ†ææ‰‹æ³•åˆ¥ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    from sqlalchemy import func

    stats = (
        db.query(
            AnalysisSession.analysis_type,
            func.count(AnalysisSession.id).label("count"),
            func.max(AnalysisSession.analysis_timestamp).label("latest_analysis"),
        )
        .group_by(AnalysisSession.analysis_type)
        .all()
    )

    return [
        {
            "analysis_type": stat.analysis_type,
            "count": stat.count,
            "latest_analysis": (
                stat.latest_analysis.isoformat() if stat.latest_analysis else None
            ),
        }
        for stat in stats
    ]


# ğŸ†• åˆ†ææ‰‹æ³•ã®å®šæ•°
class AnalysisTypes:
    CORRESPONDENCE = "correspondence"
    PCA = "pca"
    FACTOR = "factor"
    CLUSTER = "cluster"
    REGRESSION = "regression"
    RFM = "rfm"  # ğŸ†• è¿½åŠ 

    @classmethod
    def all(cls):
        return [cls.CORRESPONDENCE, cls.PCA, cls.FACTOR, cls.CLUSTER]

    @classmethod
    def is_valid(cls, analysis_type: str):
        return analysis_type in cls.all()


class SessionTag(Base):
    __tablename__ = "session_tags"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(Integer, ForeignKey("analysis_sessions.id"), nullable=False)
    tag_name = Column(String(100), nullable=False)
    created_at = Column(TIMESTAMP, default=datetime.utcnow)

    # ä¸€æ„åˆ¶ç´„
    __table_args__ = (
        UniqueConstraint("session_id", "tag_name", name="uq_session_tag"),
    )

    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    session = relationship("AnalysisSession")


# ğŸ†• ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®å®šæ•°
class MetadataTypes:
    # ä¸»æˆåˆ†åˆ†æç”¨
    PCA_LOADINGS = "pca_loadings"
    PCA_SCORES = "pca_scores"
    PCA_VARIANCE_EXPLAINED = "pca_variance_explained"

    # å› å­åˆ†æç”¨
    FACTOR_LOADINGS = "factor_loadings"
    FACTOR_SCORES = "factor_scores"
    FACTOR_ROTATION_MATRIX = "factor_rotation_matrix"

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æç”¨
    CLUSTER_CENTERS = "cluster_centers"
    CLUSTER_ASSIGNMENTS = "cluster_assignments"
    CLUSTER_METRICS = "cluster_metrics"

    # ğŸ†• å›å¸°åˆ†æç”¨
    REGRESSION_STATS = "regression_stats"
    REGRESSION_COEFFICIENTS = "regression_coefficients"
    REGRESSION_PREDICTIONS = "regression_predictions"
    REGRESSION_RESIDUALS = "regression_residuals"

    # RFMåˆ†æç”¨ã‚’è¿½åŠ 
    RFM_STATISTICS = "rfm_statistics"
    RFM_SEGMENTS = "rfm_segments"
    RFM_CUSTOMER_DATA = "rfm_customer_data"

    @classmethod
    def get_types_for_analysis(cls, analysis_type: str):
        """åˆ†ææ‰‹æ³•ã«å¯¾å¿œã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’å–å¾—"""
        type_mapping = {
            AnalysisTypes.PCA: [
                cls.PCA_LOADINGS,
                cls.PCA_SCORES,
                cls.PCA_VARIANCE_EXPLAINED,
            ],
            AnalysisTypes.FACTOR: [
                cls.FACTOR_LOADINGS,
                cls.FACTOR_SCORES,
                cls.FACTOR_ROTATION_MATRIX,
            ],
            AnalysisTypes.CLUSTER: [
                cls.CLUSTER_CENTERS,
                cls.CLUSTER_ASSIGNMENTS,
                cls.CLUSTER_METRICS,
            ],
            AnalysisTypes.REGRESSION: [
                cls.REGRESSION_STATS,
                cls.REGRESSION_COEFFICIENTS,
                cls.REGRESSION_PREDICTIONS,
                cls.REGRESSION_RESIDUALS,
            ],
            # RFMåˆ†æç”¨ã‚’è¿½åŠ 
            AnalysisTypes.RFM: [
                cls.RFM_STATISTICS,
                cls.RFM_SEGMENTS,
                cls.RFM_CUSTOMER_DATA,
            ],
        }
        return type_mapping.get(analysis_type, [])

    def get_rfm_customer_segments(db, session_id: int):
        """RFMåˆ†æã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—"""
        from sqlalchemy import func

        # é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        customers = (
            db.query(CoordinatesData)
            .filter(
                CoordinatesData.session_id == session_id,
                CoordinatesData.point_type == "customer",
            )
            .all()
        )

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥é›†è¨ˆ
        segment_summary = {}
        for customer in customers:
            if customer.metadata_json and "segment" in customer.metadata_json:
                segment = customer.metadata_json["segment"]
                if segment not in segment_summary:
                    segment_summary[segment] = {
                        "count": 0,
                        "avg_recency": 0,
                        "avg_frequency": 0,
                        "avg_monetary": 0,
                        "total_recency": 0,
                        "total_frequency": 0,
                        "total_monetary": 0,
                    }

                segment_summary[segment]["count"] += 1
                segment_summary[segment]["total_recency"] += customer.dimension_1 or 0
                segment_summary[segment]["total_frequency"] += customer.dimension_2 or 0
                segment_summary[segment]["total_monetary"] += customer.dimension_3 or 0

        # å¹³å‡å€¤ã‚’è¨ˆç®—
        for segment, data in segment_summary.items():
            if data["count"] > 0:
                data["avg_recency"] = data["total_recency"] / data["count"]
                data["avg_frequency"] = data["total_frequency"] / data["count"]
                data["avg_monetary"] = data["total_monetary"] / data["count"]

        return segment_summary

    def get_rfm_statistics(db, session_id: int):
        """RFMåˆ†æã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        metadata = (
            db.query(AnalysisMetadata)
            .filter(
                AnalysisMetadata.session_id == session_id,
                AnalysisMetadata.metadata_type == MetadataTypes.RFM_STATISTICS,
            )
            .first()
        )

        if metadata:
            return metadata.metadata_content

        return None
