from typing import Dict, Any, List, Tuple, Optional
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patheffects as pe
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    mean_squared_error,
    mean_absolute_error,
    r2_score,
)
import scipy.stats as stats
import seaborn as sns
from .base import BaseAnalyzer
from sqlalchemy.orm import Session


class RegressionAnalyzer(BaseAnalyzer):
    """å›å¸°åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def get_analysis_type(self) -> str:
        return "regression"

    def analyze(self, df: pd.DataFrame, **kwargs) -> Dict[str, Any]:
        """å›å¸°åˆ†æã‚’å®Ÿè¡Œ"""
        method = kwargs.get("method", "linear")
        target_variable = kwargs.get("target_variable")
        explanatory_variables = kwargs.get("explanatory_variables", [])
        polynomial_degree = kwargs.get("polynomial_degree", 2)
        test_size = kwargs.get("test_size", 0.2)
        random_state = kwargs.get("random_state", 42)
        include_intercept = kwargs.get("include_intercept", True)
        standardize = kwargs.get("standardize", False)

        return self.perform_analysis(
            df,
            method,
            target_variable,
            explanatory_variables,
            polynomial_degree,
            test_size,
            random_state,
            include_intercept,
            standardize,
        )

    def create_plot(self, results: Dict[str, Any], df: pd.DataFrame) -> str:
        """å›å¸°åˆ†æãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ"""
        return self.create_regression_plot(df, results)

    def run_full_analysis(
        self,
        df,
        db,
        session_name,
        description,
        tags,
        user_id,
        file,
        csv_text,
        method,
        target_variable,
        explanatory_variables,
        polynomial_degree,
        test_size,
        random_state,
        include_intercept,
        standardize,
    ):
        """å®Œå…¨ãªå›å¸°åˆ†æã‚’å®Ÿè¡Œï¼ˆå› å­åˆ†æã‚’å‚è€ƒã«ä¿®æ­£ï¼‰"""
        try:
            print("=== å›å¸°åˆ†æå®Ÿè¡Œé–‹å§‹ ===")

            # åˆ†æå®Ÿè¡Œ
            results = self.perform_analysis(
                df,
                method,
                target_variable,
                explanatory_variables,
                polynomial_degree,
                test_size,
                random_state,
                include_intercept,
                standardize,
            )

            # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
            plot_base64 = self.create_plot(results, df)
            print(f"ãƒ—ãƒ­ãƒƒãƒˆä½œæˆå®Œäº†: {len(plot_base64)} æ–‡å­—")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆå› å­åˆ†æã¨åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼‰
            session_id = self.save_to_database(
                db=db,
                session_name=session_name,
                description=description,
                tags=tags,
                user_id=user_id,
                file=file,
                csv_text=csv_text,
                df=df,
                results=results,
                plot_base64=plot_base64,
            )

            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: session_id={session_id}")

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
            response_data = self.create_response(
                results, df, session_id, session_name, file, plot_base64
            )

            print("=== å›å¸°åˆ†æå®Ÿè¡Œå®Œäº† ===")
            return response_data

        except Exception as e:
            print(f"å›å¸°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback

            traceback.print_exc()
            raise

    def save_to_database(
        self,
        db: Session,
        session_name: str,
        description: Optional[str],
        tags: List[str],
        user_id: str,
        file,
        csv_text: str,
        df: pd.DataFrame,
        results: Dict[str, Any],
        plot_base64: str,
    ) -> int:
        """å›å¸°åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆå› å­åˆ†æã‚’å‚è€ƒã«ä¿®æ­£ï¼‰"""
        try:
            print("=== å›å¸°åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜é–‹å§‹ ===")

            # åŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ã‚’ç¢ºèª
            if hasattr(super(), "save_to_database"):
                try:
                    session_id = super().save_to_database(
                        db,
                        session_name,
                        description,
                        tags,
                        user_id,
                        file,
                        csv_text,
                        df,
                        results,
                        plot_base64,
                    )
                    print(f"åŸºåº•ã‚¯ãƒ©ã‚¹ä¿å­˜æˆåŠŸ: session_id={session_id}")
                except Exception as e:
                    print(f"âš ï¸ åŸºåº•ã‚¯ãƒ©ã‚¹ã®save_to_databaseã‚¨ãƒ©ãƒ¼: {e}")
                    session_id = self._save_session_directly(
                        db,
                        session_name,
                        description,
                        tags,
                        user_id,
                        file,
                        csv_text,
                        df,
                        results,
                        plot_base64,
                    )
            else:
                print("âš ï¸ åŸºåº•ã‚¯ãƒ©ã‚¹ã«save_to_databaseãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
                session_id = self._save_session_directly(
                    db,
                    session_name,
                    description,
                    tags,
                    user_id,
                    file,
                    csv_text,
                    df,
                    results,
                    plot_base64,
                )

            if session_id == 0:
                raise Exception("session_idãŒ0ã§ã™ã€‚ä¿å­˜ã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            # å›å¸°åˆ†æç‰¹æœ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ä¿å­˜
            self._save_regression_specific_data(db, session_id, results)

            # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆäºˆæ¸¬çµæœï¼‰
            self._save_coordinates_data(db, session_id, df, results)

            print(f"=== å›å¸°åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: session_id={session_id} ===")
            return session_id

        except Exception as e:
            print(f"âŒ å›å¸°åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback

            print(f"è©³ç´°:\n{traceback.format_exc()}")
            return 0

    def _save_session_directly(
        self,
        db: Session,
        session_name: str,
        description: Optional[str],
        tags: List[str],
        user_id: str,
        file,
        csv_text: str,
        df: pd.DataFrame,
        results: Dict[str, Any],
        plot_base64: str,
    ) -> int:
        """åŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒãªã„å ´åˆã®ç›´æ¥ä¿å­˜ï¼ˆå› å­åˆ†æã‚’å‚è€ƒï¼‰"""
        try:
            from models import AnalysisSession, VisualizationData

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åŸºæœ¬æƒ…å ±ã‚’ä¿å­˜
            session = AnalysisSession(
                session_name=session_name,
                description=description,
                analysis_type=self.get_analysis_type(),
                original_filename=file.filename,
                user_id=user_id,
                row_count=df.shape[0],
                column_count=df.shape[1],
                # å›å¸°åˆ†æç‰¹æœ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                dimensions_count=len(results.get("explanatory_variables", [])),
                dimension_1_contribution=results.get("r2_all", 0.0),
                standardized=results.get("standardize", False),
            )

            db.add(session)
            db.flush()  # IDã‚’å–å¾—ã™ã‚‹ãŸã‚
            session_id = session.id

            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆæˆåŠŸ: session_id={session_id}")

            # ã‚¿ã‚°ã‚’ä¿å­˜
            if tags:
                from models import SessionTag

                for tag in tags:
                    if tag.strip():
                        session_tag = SessionTag(
                            session_id=session_id, tag_name=tag.strip()
                        )
                        db.add(session_tag)

            # ãƒ—ãƒ­ãƒƒãƒˆç”»åƒã‚’ä¿å­˜
            if plot_base64:
                visualization = VisualizationData(
                    session_id=session_id,
                    image_base64=plot_base64,
                    width=1400,
                    height=1100,
                    image_type="regression_plot",
                )
                db.add(visualization)

            db.commit()
            print(f"ç›´æ¥ä¿å­˜å®Œäº†: session_id={session_id}")
            return session_id

        except Exception as e:
            print(f"âŒ ç›´æ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            db.rollback()
            return 0

    def _save_regression_specific_data(
        self, db: Session, session_id: int, results: Dict[str, Any]
    ):
        """å›å¸°åˆ†æç‰¹æœ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            from models import AnalysisMetadata

            # å›å¸°çµ±è¨ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            stats_data = {
                "r2_score": float(results.get("r2_all", 0.0)),
                "adjusted_r2": float(results.get("adjusted_r2", 0.0)),
                "mse": float(
                    mean_squared_error(results["y_processed"], results["y_pred_all"])
                ),
                "mae": float(
                    mean_absolute_error(results["y_processed"], results["y_pred_all"])
                ),
                "rmse": float(
                    np.sqrt(
                        mean_squared_error(
                            results["y_processed"], results["y_pred_all"]
                        )
                    )
                ),
                "method": results.get("method", "linear"),
                "target_variable": results.get("target_variable", ""),
                "explanatory_variables": results.get("explanatory_variables", []),
            }

            # Fçµ±è¨ˆé‡ã¨på€¤ã‚’è¿½åŠ ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            if results.get("f_statistic") is not None:
                stats_data["f_statistic"] = float(results["f_statistic"])
            if results.get("p_value") is not None:
                stats_data["p_value"] = float(results["p_value"])

            stats_metadata = AnalysisMetadata(
                session_id=session_id,
                metadata_type="regression_stats",
                metadata_content=stats_data,
            )
            db.add(stats_metadata)

            # å›å¸°ä¿‚æ•°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            if "coefficients" in results:
                coeffs_metadata = AnalysisMetadata(
                    session_id=session_id,
                    metadata_type="regression_coefficients",
                    metadata_content=results["coefficients"],
                )
                db.add(coeffs_metadata)

            db.commit()
            print(f"å›å¸°ç‰¹æœ‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: session_id={session_id}")

        except Exception as e:
            print(f"å›å¸°ç‰¹æœ‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            db.rollback()

    def _save_coordinates_data(
        self, db: Session, session_id: int, df: pd.DataFrame, results: Dict[str, Any]
    ):
        """å›å¸°åˆ†æã®äºˆæ¸¬çµæœä¿å­˜ï¼ˆå› å­åˆ†æã‚’å‚è€ƒã«ä¿®æ­£ï¼‰"""
        try:
            from models import CoordinatesData

            y_true = results["y_processed"]
            y_pred = results["y_pred_all"]
            train_idx = results["y_train"].index
            test_idx = results["y_test"].index

            print(f"=== å›å¸°äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ä¿å­˜é–‹å§‹ ===")
            print(f"äºˆæ¸¬çµæœ: {len(y_pred)} ä»¶")

            # äºˆæ¸¬çµæœã‚’åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
            for i, sample_name in enumerate(y_true.index):
                actual_val = float(y_true.iloc[i])
                predicted_val = float(y_pred[i])
                residual = actual_val - predicted_val
                data_type = "train" if sample_name in train_idx else "test"

                coord_data = CoordinatesData(
                    session_id=session_id,
                    point_name=str(sample_name),
                    point_type=data_type,
                    dimension_1=actual_val,  # å®Ÿéš›å€¤
                    dimension_2=predicted_val,  # äºˆæ¸¬å€¤
                    dimension_3=residual,  # æ®‹å·®
                )
                db.add(coord_data)

            db.commit()
            print(f"âœ… å›å¸°äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {len(y_pred)} ä»¶")

        except Exception as e:
            print(f"âŒ å›å¸°äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback

            print(f"è©³ç´°:\n{traceback.format_exc()}")
            db.rollback()

    def perform_analysis(
        self,
        df,
        method,
        target_variable,
        explanatory_variables,
        polynomial_degree,
        test_size,
        random_state,
        include_intercept,
        standardize,
    ):
        """å›å¸°åˆ†æå®Ÿè¡Œ"""
        print(
            f"åˆ†æé–‹å§‹: method={method}, target={target_variable}, explanatory={explanatory_variables}"
        )

        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        y = df[target_variable].copy()
        X = df[explanatory_variables].copy()

        # å…ƒã®Xã‚’ä¿å­˜ï¼ˆãƒ—ãƒ­ãƒƒãƒˆç”¨ï¼‰
        original_X = X.copy()

        # æ¬ æå€¤ã®ç¢ºèªã¨é™¤å»
        data_combined = pd.concat([X, y], axis=1)
        data_combined = data_combined.dropna()

        if len(data_combined) == 0:
            raise ValueError("æ¬ æå€¤ã‚’é™¤å»ã—ãŸçµæœã€æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        X = data_combined[explanatory_variables]
        y = data_combined[target_variable]

        print(f"æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿æ•°: {len(X)}")

        # æ¨™æº–åŒ–
        scaler = None
        if standardize and method in ["multiple"]:
            scaler = StandardScaler()
            X = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)

        # å¤šé …å¼ç‰¹å¾´é‡ç”Ÿæˆ
        poly_features = None
        if method == "polynomial":
            poly_features = PolynomialFeatures(
                degree=polynomial_degree, include_bias=include_intercept
            )
            X_poly = poly_features.fit_transform(X)
            X = pd.DataFrame(
                X_poly,
                index=X.index,
                columns=[f"x^{i}" for i in range(X_poly.shape[1])],
            )

        # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )

        # å›å¸°ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
        model = LinearRegression(
            fit_intercept=include_intercept and method != "polynomial"
        )
        model.fit(X_train, y_train)

        # äºˆæ¸¬
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)
        y_pred_all = model.predict(X)

        # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
        r2_train = r2_score(y_train, y_train_pred)
        r2_test = r2_score(y_test, y_test_pred)
        r2_all = r2_score(y, y_pred_all)

        mse_train = mean_squared_error(y_train, y_train_pred)
        mse_test = mean_squared_error(y_test, y_test_pred)
        mae_train = mean_absolute_error(y_train, y_train_pred)
        mae_test = mean_absolute_error(y_test, y_test_pred)

        rmse_train = np.sqrt(mse_train)
        rmse_test = np.sqrt(mse_test)

        # èª¿æ•´æ¸ˆã¿æ±ºå®šä¿‚æ•°
        n = len(X)
        p = X.shape[1]
        adjusted_r2 = 1 - (1 - r2_all) * (n - 1) / (n - p - 1) if n > p + 1 else r2_all

        # å›å¸°ä¿‚æ•°ã¨çµ±è¨ˆçš„æ¤œå®š
        coefficients = self.calculate_coefficient_statistics(
            X, y, model, include_intercept
        )

        # Fçµ±è¨ˆé‡ã¨på€¤
        f_stat, p_value = self.calculate_f_statistic(y, y_pred_all, X.shape[1])

        print(
            f"è©•ä¾¡æŒ‡æ¨™ - RÂ²: {r2_all:.4f}, RMSE: {np.sqrt(mean_squared_error(y, y_pred_all)):.4f}"
        )

        return {
            "method": method,
            "target_variable": target_variable,
            "explanatory_variables": explanatory_variables,
            "polynomial_degree": polynomial_degree if method == "polynomial" else None,
            "include_intercept": include_intercept,
            "standardize": standardize,
            "model": model,
            "scaler": scaler,
            "poly_features": poly_features,
            "original_X": original_X,
            "X_train": X_train,
            "X_test": X_test,
            "y_train": y_train,
            "y_test": y_test,
            "y_train_pred": y_train_pred,
            "y_test_pred": y_test_pred,
            "y_pred_all": y_pred_all,
            "X_processed": X,
            "y_processed": y,
            "r2_train": r2_train,
            "r2_test": r2_test,
            "r2_all": r2_all,
            "adjusted_r2": adjusted_r2,
            "mse_train": mse_train,
            "mse_test": mse_test,
            "mae_train": mae_train,
            "mae_test": mae_test,
            "rmse_train": rmse_train,
            "rmse_test": rmse_test,
            "coefficients": coefficients,
            "f_statistic": f_stat,
            "p_value": p_value,
        }

    def calculate_coefficient_statistics(self, X, y, model, include_intercept):
        """å›å¸°ä¿‚æ•°ã®çµ±è¨ˆçš„æ¤œå®šã‚’è¨ˆç®—"""
        try:
            n = len(X)
            p = X.shape[1]

            # äºˆæ¸¬å€¤ã¨æ®‹å·®
            y_pred = model.predict(X)
            residuals = y - y_pred

            # æ®‹å·®ã®æ¨™æº–èª¤å·®
            mse = np.sum(residuals**2) / (n - p - (1 if include_intercept else 0))

            # ãƒ‡ã‚¶ã‚¤ãƒ³è¡Œåˆ—
            if include_intercept:
                X_design = np.column_stack([np.ones(n), X])
                coef_names = ["åˆ‡ç‰‡"] + list(X.columns)
                coeffs = np.concatenate([[model.intercept_], model.coef_])
            else:
                X_design = X.values
                coef_names = list(X.columns)
                coeffs = model.coef_

            # å…±åˆ†æ•£è¡Œåˆ—
            try:
                cov_matrix = mse * np.linalg.inv(X_design.T @ X_design)
                std_errors = np.sqrt(np.diag(cov_matrix))

                # tçµ±è¨ˆé‡ã¨på€¤
                t_values = coeffs / std_errors
                df = n - len(coeffs)
                p_values = 2 * (1 - stats.t.cdf(np.abs(t_values), df))

                result = {}
                for i, name in enumerate(coef_names):
                    result[name] = {
                        "coefficient": float(coeffs[i]),
                        "std_error": float(std_errors[i]),
                        "t_value": float(t_values[i]),
                        "p_value": float(p_values[i]),
                    }

                return result

            except np.linalg.LinAlgError:
                # ç‰¹ç•°è¡Œåˆ—ã®å ´åˆã¯ä¿‚æ•°ã®ã¿è¿”ã™
                result = {}
                for i, name in enumerate(coef_names):
                    result[name] = {
                        "coefficient": float(coeffs[i]),
                        "std_error": None,
                        "t_value": None,
                        "p_value": None,
                    }
                return result

        except Exception as e:
            print(f"ä¿‚æ•°çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¿‚æ•°ã®ã¿
            if include_intercept:
                return {
                    "åˆ‡ç‰‡": {"coefficient": float(model.intercept_)},
                    **{
                        col: {"coefficient": float(coef)}
                        for col, coef in zip(X.columns, model.coef_)
                    },
                }
            else:
                return {
                    col: {"coefficient": float(coef)}
                    for col, coef in zip(X.columns, model.coef_)
                }

    def calculate_f_statistic(self, y_true, y_pred, p):
        """Fçµ±è¨ˆé‡ã¨på€¤ã‚’è¨ˆç®—"""
        try:
            n = len(y_true)

            # å…¨å¹³å‡
            y_mean = np.mean(y_true)

            # å¹³æ–¹å’Œ
            sst = np.sum((y_true - y_mean) ** 2)  # ç·å¹³æ–¹å’Œ
            ssr = np.sum((y_pred - y_mean) ** 2)  # å›å¸°å¹³æ–¹å’Œ
            sse = np.sum((y_true - y_pred) ** 2)  # èª¤å·®å¹³æ–¹å’Œ

            # è‡ªç”±åº¦
            df_reg = p  # å›å¸°ã®è‡ªç”±åº¦
            df_res = n - p - 1  # æ®‹å·®ã®è‡ªç”±åº¦

            if df_res <= 0:
                return None, None

            # Fçµ±è¨ˆé‡
            msr = ssr / df_reg  # å›å¸°å¹³å‡å¹³æ–¹
            mse = sse / df_res  # èª¤å·®å¹³å‡å¹³æ–¹

            if mse == 0:
                return None, None

            f_stat = msr / mse

            # på€¤
            p_value = 1 - stats.f.cdf(f_stat, df_reg, df_res)

            return float(f_stat), float(p_value)

        except Exception as e:
            print(f"Fçµ±è¨ˆé‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, None

    def create_regression_plot(self, df, results):
        """å›å¸°åˆ†æãƒ—ãƒ­ãƒƒãƒˆç”»åƒã‚’ç”Ÿæˆã—ã¦base64ã§è¿”ã™"""
        import warnings

        warnings.filterwarnings("ignore")

        try:
            print("=== å›å¸°ãƒ—ãƒ­ãƒƒãƒˆç”»åƒç”Ÿæˆé–‹å§‹ ===")

            method = results["method"]
            target_var = results["target_variable"]
            explanatory_vars = results["explanatory_variables"]

            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            self.setup_japanese_font()

            # å›³ã®ã‚µã‚¤ã‚ºè¨­å®š
            fig = plt.figure(figsize=(16, 12))

            if method == "linear" or (
                method == "polynomial" and len(explanatory_vars) == 1
            ):
                # å˜å›å¸°ãƒ»å¤šé …å¼å›å¸°ã®å ´åˆï¼ˆ2x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰

                # 1. æ•£å¸ƒå›³ã¨å›å¸°ç›´ç·š/æ›²ç·š
                ax1 = plt.subplot(2, 2, 1)
                self.plot_regression_line(results, ax1)

                # 2. æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
                ax2 = plt.subplot(2, 2, 2)
                self.plot_residuals(results, ax2)

                # 3. Q-Qãƒ—ãƒ­ãƒƒãƒˆ
                ax3 = plt.subplot(2, 2, 3)
                self.plot_qq(results, ax3)

                # 4. è©•ä¾¡æŒ‡æ¨™ã¾ã¨ã‚
                ax4 = plt.subplot(2, 2, 4)
                self.plot_regression_metrics(results, ax4)

            else:
                # é‡å›å¸°ã®å ´åˆï¼ˆ2x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰

                # 1. å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤
                ax1 = plt.subplot(2, 2, 1)
                self.plot_actual_vs_predicted(results, ax1)

                # 2. æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
                ax2 = plt.subplot(2, 2, 2)
                self.plot_residuals_multiple(results, ax2)

                # 3. ä¿‚æ•°ã®é‡è¦åº¦
                ax3 = plt.subplot(2, 2, 3)
                self.plot_coefficients(results, ax3)

                # 4. è©•ä¾¡æŒ‡æ¨™ã¾ã¨ã‚
                ax4 = plt.subplot(2, 2, 4)
                self.plot_regression_metrics(results, ax4)

            plt.tight_layout()

            # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            return self.save_plot_as_base64(fig)

        except Exception as e:
            print(f"å›å¸°ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback

            traceback.print_exc()
            return ""

    def plot_regression_line(self, results, ax):
        """å›å¸°ç›´ç·š/æ›²ç·šãƒ—ãƒ­ãƒƒãƒˆï¼ˆå˜å›å¸°ãƒ»å¤šé …å¼å›å¸°ç”¨ï¼‰"""
        try:
            X = results["X_processed"]
            y = results["y_processed"]
            y_pred = results["y_pred_all"]
            method = results["method"]

            if method == "polynomial":
                # å¤šé …å¼å›å¸°ã®å ´åˆã€å…ƒã®èª¬æ˜å¤‰æ•°ã‚’å–å¾—
                explanatory_var = results["explanatory_variables"][0]

                # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰èª¬æ˜å¤‰æ•°ã®å€¤ã‚’å–å¾—
                original_X = results.get("original_X")
                if original_X is not None and explanatory_var in original_X.columns:
                    x_values = original_X[explanatory_var].values
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰æ¨æ¸¬
                    x_values = np.arange(len(y))

                # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦ã‚½ãƒ¼ãƒˆ
                combined_data = pd.DataFrame(
                    {"x": x_values, "y_actual": y.values, "y_pred": y_pred}
                )
                combined_data = combined_data.sort_values("x")

                ax.scatter(
                    combined_data["x"],
                    combined_data["y_actual"],
                    alpha=0.6,
                    label="å®Ÿæ¸¬å€¤",
                    color="blue",
                )
                ax.plot(
                    combined_data["x"],
                    combined_data["y_pred"],
                    color="red",
                    linewidth=2,
                    label=f"å¤šé …å¼å›å¸°(æ¬¡æ•°={results['polynomial_degree']})",
                )

                ax.set_xlabel(explanatory_var, fontsize=12)
            else:
                # å˜å›å¸°ã®å ´åˆ
                x_values = X.iloc[:, 0].values
                y_values = y.values

                # ã‚½ãƒ¼ãƒˆã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ
                sort_idx = np.argsort(x_values)
                x_sorted = x_values[sort_idx]
                y_sorted = y_values[sort_idx]
                y_pred_sorted = y_pred[sort_idx]

                ax.scatter(x_values, y_values, alpha=0.6, label="å®Ÿæ¸¬å€¤", color="blue")
                ax.plot(
                    x_sorted, y_pred_sorted, color="red", linewidth=2, label="å›å¸°ç›´ç·š"
                )

                ax.set_xlabel(results["explanatory_variables"][0], fontsize=12)

            ax.set_ylabel(results["target_variable"], fontsize=12)
            ax.set_title(
                f"å›å¸°åˆ†æçµæœ (RÂ² = {results['r2_all']:.3f})",
                fontsize=14,
                fontweight="bold",
            )
            ax.legend()
            ax.grid(True, alpha=0.3)

        except Exception as e:
            ax.text(
                0.5,
                0.5,
                f"å›å¸°ç›´ç·šãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                transform=ax.transAxes,
                ha="center",
                va="center",
            )

    def plot_actual_vs_predicted(self, results, ax):
        """å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤ãƒ—ãƒ­ãƒƒãƒˆï¼ˆé‡å›å¸°ç”¨ï¼‰"""
        try:
            y_true = results["y_processed"]
            y_pred = results["y_pred_all"]

            # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åŒºåˆ¥
            train_idx = results["y_train"].index
            test_idx = results["y_test"].index

            # å®‰å…¨ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ“ä½œ
            y_true_values = y_true.values
            train_positions = []
            test_positions = []

            for i, idx in enumerate(y_true.index):
                if idx in train_idx:
                    train_positions.append(i)
                elif idx in test_idx:
                    test_positions.append(i)

            train_positions = np.array(train_positions)
            test_positions = np.array(test_positions)

            if len(train_positions) > 0:
                ax.scatter(
                    y_true_values[train_positions],
                    y_pred[train_positions],
                    alpha=0.6,
                    label="è¨“ç·´ãƒ‡ãƒ¼ã‚¿",
                    color="blue",
                )
            if len(test_positions) > 0:
                ax.scatter(
                    y_true_values[test_positions],
                    y_pred[test_positions],
                    alpha=0.6,
                    label="ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿",
                    color="red",
                )

            # ç†æƒ³ç·šï¼ˆy=xï¼‰
            min_val = min(y_true_values.min(), y_pred.min())
            max_val = max(y_true_values.max(), y_pred.max())
            ax.plot(
                [min_val, max_val],
                [min_val, max_val],
                "k--",
                linewidth=1,
                label="ç†æƒ³ç·š (y=x)",
            )

            ax.set_xlabel("å®Ÿæ¸¬å€¤", fontsize=12)
            ax.set_ylabel("äºˆæ¸¬å€¤", fontsize=12)
            ax.set_title(
                f"å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤ (RÂ² = {results['r2_all']:.3f})",
                fontsize=14,
                fontweight="bold",
            )
            ax.legend()
            ax.grid(True, alpha=0.3)

        except Exception as e:
            ax.text(
                0.5,
                0.5,
                f"å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                transform=ax.transAxes,
                ha="center",
                va="center",
            )

    def plot_residuals(self, results, ax):
        """æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå˜å›å¸°ãƒ»å¤šé …å¼å›å¸°ç”¨ï¼‰"""
        try:
            y_true = results["y_processed"]
            y_pred = results["y_pred_all"]
            residuals = y_true.values - y_pred

            if results["method"] == "polynomial":
                # å¤šé …å¼å›å¸°ã®å ´åˆã€å…ƒã®èª¬æ˜å¤‰æ•°ã‚’ä½¿ç”¨
                original_X = results.get("original_X")
                explanatory_var = results["explanatory_variables"][0]

                if original_X is not None and explanatory_var in original_X.columns:
                    x_vals = original_X[explanatory_var].values
                else:
                    x_vals = np.arange(len(residuals))
            else:
                X = results["X_processed"]
                x_vals = X.iloc[:, 0].values

            ax.scatter(x_vals, residuals, alpha=0.6, color="blue")
            ax.axhline(y=0, color="red", linestyle="--", linewidth=1)

            ax.set_xlabel(results["explanatory_variables"][0], fontsize=12)
            ax.set_ylabel("æ®‹å·®", fontsize=12)
            ax.set_title("æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ", fontsize=14, fontweight="bold")
            ax.grid(True, alpha=0.3)

        except Exception as e:
            ax.text(
                0.5,
                0.5,
                f"æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                transform=ax.transAxes,
                ha="center",
                va="center",
            )

    def plot_residuals_multiple(self, results, ax):
        """æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆé‡å›å¸°ç”¨ï¼‰"""
        try:
            y_pred = results["y_pred_all"]
            y_true = results["y_processed"]
            residuals = y_true.values - y_pred

            ax.scatter(y_pred, residuals, alpha=0.6, color="blue")
            ax.axhline(y=0, color="red", linestyle="--", linewidth=1)

            ax.set_xlabel("äºˆæ¸¬å€¤", fontsize=12)
            ax.set_ylabel("æ®‹å·®", fontsize=12)
            ax.set_title("æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ", fontsize=14, fontweight="bold")
            ax.grid(True, alpha=0.3)

        except Exception as e:
            ax.text(
                0.5,
                0.5,
                f"æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                transform=ax.transAxes,
                ha="center",
                va="center",
            )

    def plot_qq(self, results, ax):
        """Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ­£è¦æ€§ã®ç¢ºèªï¼‰"""
        try:
            y_true = results["y_processed"]
            y_pred = results["y_pred_all"]
            residuals = y_true.values - y_pred

            stats.probplot(residuals, dist="norm", plot=ax)
            ax.set_title("Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ®‹å·®ã®æ­£è¦æ€§ï¼‰", fontsize=14, fontweight="bold")
            ax.grid(True, alpha=0.3)

        except Exception as e:
            ax.text(
                0.5,
                0.5,
                f"Q-Qãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                transform=ax.transAxes,
                ha="center",
                va="center",
            )

    def plot_coefficients(self, results, ax):
        """å›å¸°ä¿‚æ•°ã®é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ"""
        try:
            coefficients = results["coefficients"]

            # åˆ‡ç‰‡ä»¥å¤–ã®ä¿‚æ•°ã‚’å–å¾—
            coef_data = {
                k: v["coefficient"]
                for k, v in coefficients.items()
                if k != "åˆ‡ç‰‡" and "coefficient" in v
            }

            if not coef_data:
                ax.text(
                    0.5,
                    0.5,
                    "è¡¨ç¤ºå¯èƒ½ãªä¿‚æ•°ãŒã‚ã‚Šã¾ã›ã‚“",
                    transform=ax.transAxes,
                    ha="center",
                    va="center",
                )
                return

            names = list(coef_data.keys())
            values = list(coef_data.values())
            colors = ["red" if v < 0 else "blue" for v in values]

            bars = ax.barh(names, values, color=colors, alpha=0.7)

            # å€¤ã‚’ãƒãƒ¼ã®ç«¯ã«è¡¨ç¤º
            for bar, value in zip(bars, values):
                width = bar.get_width()
                ax.text(
                    width + (0.01 * max(abs(min(values)), abs(max(values)))),
                    bar.get_y() + bar.get_height() / 2,
                    f"{value:.3f}",
                    ha="left" if width >= 0 else "right",
                    va="center",
                )

            ax.axvline(x=0, color="black", linestyle="-", linewidth=0.5)
            ax.set_xlabel("å›å¸°ä¿‚æ•°", fontsize=12)
            ax.set_title("å›å¸°ä¿‚æ•°", fontsize=14, fontweight="bold")
            ax.grid(True, alpha=0.3, axis="x")

        except Exception as e:
            ax.text(
                0.5,
                0.5,
                f"ä¿‚æ•°ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                transform=ax.transAxes,
                ha="center",
                va="center",
            )

    def plot_regression_metrics(self, results, ax):
        """è©•ä¾¡æŒ‡æ¨™ã¾ã¨ã‚ãƒ—ãƒ­ãƒƒãƒˆ"""
        try:
            metrics = {
                "RÂ²": results["r2_all"],
                "èª¿æ•´æ¸ˆã¿RÂ²": results["adjusted_r2"],
                "RMSE": np.sqrt(
                    mean_squared_error(results["y_processed"], results["y_pred_all"])
                ),
            }

            # æ­£è¦åŒ–ï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            normalized_metrics = {}
            normalized_metrics["RÂ²"] = max(0, metrics["RÂ²"])
            normalized_metrics["èª¿æ•´æ¸ˆã¿RÂ²"] = max(0, metrics["èª¿æ•´æ¸ˆã¿RÂ²"])

            # RMSEã¯æ¨™æº–åå·®ã§æ­£è¦åŒ–
            y_std = results["y_processed"].std()
            normalized_metrics["RMSE"] = max(0, 1 - (metrics["RMSE"] / y_std))

            names = list(normalized_metrics.keys())
            values = list(normalized_metrics.values())
            colors = ["#2E86AB", "#A23B72", "#F18F01"]

            bars = ax.bar(
                names, values, color=colors, alpha=0.8, edgecolor="black", linewidth=1
            )

            # å…ƒã®å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
            for bar, name in zip(bars, names):
                height = bar.get_height()
                original_val = metrics[name]
                ax.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    height + 0.01,
                    f"{original_val:.3f}",
                    ha="center",
                    va="bottom",
                    fontweight="bold",
                )

            ax.set_ylabel("æ­£è¦åŒ–ã‚¹ã‚³ã‚¢", fontsize=12)
            ax.set_title("è©•ä¾¡æŒ‡æ¨™", fontsize=14, fontweight="bold")
            ax.set_ylim(0, 1.2)
            ax.grid(True, alpha=0.3, axis="y")

        except Exception as e:
            ax.text(
                0.5,
                0.5,
                f"è©•ä¾¡æŒ‡æ¨™ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                transform=ax.transAxes,
                ha="center",
                va="center",
            )

    def create_response(self, results, df, session_id, session_name, file, plot_base64):
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        try:
            # äºˆæ¸¬çµæœã®ä½œæˆ
            predictions = []
            y_true = results["y_processed"]
            y_pred = results["y_pred_all"]
            train_idx = results["y_train"].index
            test_idx = results["y_test"].index

            for i, sample_name in enumerate(y_true.index):
                actual_val = float(y_true.iloc[i])
                predicted_val = float(y_pred[i])
                residual = actual_val - predicted_val
                data_type = "train" if sample_name in train_idx else "test"

                predictions.append(
                    {
                        "sample_name": str(sample_name),
                        "actual_value": actual_val,
                        "predicted_value": predicted_val,
                        "residual": residual,
                        "data_type": data_type,
                    }
                )

            # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
            evaluation_metrics = {
                "r2_score": float(results["r2_all"]),
                "adjusted_r2": float(results["adjusted_r2"]),
                "mse": float(mean_squared_error(y_true.values, y_pred)),
                "mae": float(mean_absolute_error(y_true.values, y_pred)),
                "rmse": float(np.sqrt(mean_squared_error(y_true.values, y_pred))),
                "train_r2": float(results["r2_train"]),
                "test_r2": float(results["r2_test"]),
                "train_rmse": float(results["rmse_train"]),
                "test_rmse": float(results["rmse_test"]),
            }

            # Fçµ±è¨ˆé‡ã¨på€¤ã‚’è¿½åŠ ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            if results.get("f_statistic") is not None:
                evaluation_metrics["f_statistic"] = float(results["f_statistic"])
            if results.get("p_value") is not None:
                evaluation_metrics["p_value"] = float(results["p_value"])

            # å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿
            visualization_data = {
                "plot_image": plot_base64,
                "predictions": predictions,
                "coefficients": self._serialize_dict(results.get("coefficients", {})),
                "evaluation_metrics": evaluation_metrics,
            }

            response_data = {
                "status": "success",
                "success": True,
                "message": "å›å¸°åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ",
                "session_id": session_id,
                "session_name": session_name,
                "analysis_type": "regression",
                "metadata": {
                    "session_name": session_name,
                    "original_filename": file.filename,
                    "analysis_type": "regression",
                    "rows": int(len(y_true)),
                    "columns": int(df.shape[1]),
                    "column_names": [str(col) for col in df.columns.tolist()],
                },
                "analysis_results": {
                    "method": results["method"],
                    "target_variable": results["target_variable"],
                    "explanatory_variables": results["explanatory_variables"],
                    "polynomial_degree": results.get("polynomial_degree"),
                    "r2_score": float(results["r2_all"]),
                    "adjusted_r2": float(results["adjusted_r2"]),
                    "rmse": float(np.sqrt(mean_squared_error(y_true.values, y_pred))),
                    "coefficients": self._serialize_dict(
                        results.get("coefficients", {})
                    ),
                    "evaluation_metrics": evaluation_metrics,
                },
                "data_info": {
                    "original_filename": file.filename,
                    "rows": int(len(y_true)),
                    "columns": int(df.shape[1]),
                    "column_names": [str(col) for col in df.columns.tolist()],
                    "target_variable": results["target_variable"],
                    "explanatory_variables": results["explanatory_variables"],
                },
                "visualization": visualization_data,
            }

            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: session_id={session_id}")
            return response_data

        except Exception as e:
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback

            traceback.print_exc()
            raise

    def _serialize_dict(self, data):
        """è¾æ›¸å†…ã®numpyå‹ã‚’Pythonãƒã‚¤ãƒ†ã‚£ãƒ–å‹ã«å¤‰æ›"""
        import numpy as np

        if isinstance(data, dict):
            return {str(k): self._serialize_dict(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._serialize_dict(item) for item in data]
        elif isinstance(data, (np.integer, np.int32, np.int64)):
            return int(data)
        elif isinstance(data, (np.floating, np.float32, np.float64)):
            return float(data)
        elif isinstance(data, np.ndarray):
            return data.tolist()
        else:
            return data

    async def get_session_detail(self, session_id: int, db: Session):
        """å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ï¼ˆå› å­åˆ†æã‚’å‚è€ƒã«è¿½åŠ ï¼‰"""
        try:
            print(f"ğŸ“Š å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—é–‹å§‹: {session_id}")

            # åŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if hasattr(super(), "get_session_detail"):
                try:
                    base_detail = super().get_session_detail(db, session_id)
                except Exception as e:
                    print(f"âš ï¸ åŸºåº•ã‚¯ãƒ©ã‚¹ã®get_session_detailã‚¨ãƒ©ãƒ¼: {e}")
                    base_detail = await self._get_session_detail_directly(
                        db, session_id
                    )
            else:
                print("âš ï¸ åŸºåº•ã‚¯ãƒ©ã‚¹ã«get_session_detailãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
                base_detail = await self._get_session_detail_directly(db, session_id)

            if not base_detail or not base_detail.get("success"):
                return base_detail

            print(f"âœ… å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—å®Œäº†")
            return base_detail

        except Exception as e:
            print(f"âŒ å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback

            print(f"è©³ç´°:\n{traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    async def _get_session_detail_directly(self, db: Session, session_id: int):
        """å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’ç›´æ¥å–å¾—"""
        try:
            from models import (
                AnalysisSession,
                VisualizationData,
                CoordinatesData,
                AnalysisMetadata,
            )

            print(f"ğŸ“Š å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—é–‹å§‹: {session_id}")

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åŸºæœ¬æƒ…å ±ã‚’å–å¾—
            session = (
                db.query(AnalysisSession)
                .filter(AnalysisSession.id == session_id)
                .first()
            )

            if not session:
                return {
                    "success": False,
                    "error": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                }

            print(f"âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³åŸºæœ¬æƒ…å ±å–å¾—: {session.session_name}")

            # å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            visualization = (
                db.query(VisualizationData)
                .filter(VisualizationData.session_id == session_id)
                .first()
            )

            # äºˆæ¸¬çµæœãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            predictions = (
                db.query(CoordinatesData)
                .filter(CoordinatesData.session_id == session_id)
                .all()
            )

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            metadata_entries = (
                db.query(AnalysisMetadata)
                .filter(AnalysisMetadata.session_id == session_id)
                .all()
            )

            print(
                f"ğŸ” ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ: äºˆæ¸¬={len(predictions)}ä»¶, å¯è¦–åŒ–={'ã‚ã‚Š' if visualization else 'ãªã—'}, ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿={len(metadata_entries)}ä»¶"
            )

            # äºˆæ¸¬çµæœãƒ‡ãƒ¼ã‚¿ã®æ•´ç†
            prediction_data = []
            for pred in predictions:
                actual = pred.dimension_1 if pred.dimension_1 is not None else 0
                predicted = pred.dimension_2 if pred.dimension_2 is not None else 0
                residual = (
                    pred.dimension_3
                    if pred.dimension_3 is not None
                    else (actual - predicted)
                )

                prediction_data.append(
                    {
                        "sample_name": pred.point_name,
                        "actual_value": float(actual),
                        "predicted_value": float(predicted),
                        "residual": float(residual),
                        "data_type": pred.point_type,
                    }
                )

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†
            regression_stats = {}
            regression_coefficients = {}

            for meta in metadata_entries:
                if meta.metadata_type == "regression_stats":
                    regression_stats = meta.metadata_content
                elif meta.metadata_type == "regression_coefficients":
                    regression_coefficients = meta.metadata_content

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚’æ§‹ç¯‰
            response_data = {
                "success": True,
                "data": {
                    "session_info": {
                        "session_id": session.id,
                        "session_name": session.session_name,
                        "description": getattr(session, "description", "") or "",
                        "filename": session.original_filename,
                        "row_count": getattr(
                            session, "row_count", len(prediction_data)
                        ),
                        "column_count": getattr(session, "column_count", 2),
                        "analysis_timestamp": (
                            session.analysis_timestamp.isoformat()
                            if hasattr(session, "analysis_timestamp")
                            and session.analysis_timestamp
                            else None
                        ),
                        "method": regression_stats.get("method", "linear"),
                        "target_variable": regression_stats.get("target_variable", ""),
                        "explanatory_variables": regression_stats.get(
                            "explanatory_variables", []
                        ),
                    },
                    "metadata": {
                        "filename": session.original_filename,
                        "rows": getattr(session, "row_count", len(prediction_data)),
                        "columns": getattr(session, "column_count", 2),
                        "analysis_type": "regression",
                    },
                    "analysis_results": {
                        "evaluation_metrics": regression_stats,
                        "coefficients": regression_coefficients,
                        "predictions": prediction_data,
                    },
                    "visualization": {
                        "plot_image": (
                            visualization.image_base64 if visualization else None
                        ),
                        "width": visualization.width if visualization else 1400,
                        "height": visualization.height if visualization else 1100,
                    },
                },
            }

            print(f"âœ… å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—å®Œäº†")
            return response_data

        except Exception as e:
            print(f"âŒ å›å¸°åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback

            print(f"è©³ç´°:\n{traceback.format_exc()}")
            return {"success": False, "error": str(e)}
